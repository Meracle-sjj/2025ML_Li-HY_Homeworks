{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "WMksFjyDhCyG",
        "tags": []
      },
      "source": [
        "# Machine Learning Course 2025 HW2\n",
        "The code scripts are from [aideml](https://github.com/WecoAI/aideml) project on github with some modifications.\n",
        "\n",
        "AIDE: AI-Driven Exploration in the Space of Code\n",
        "\n",
        "https://arxiv.org/pdf/2502.13138\n",
        "\n",
        "\n",
        "<font color='red' size=6>Make a copy before running or editing the code.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubu98XRV3kCe"
      },
      "source": [
        "## Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "editable": true,
        "id": "qY6jmqu4Nhy0",
        "outputId": "04accac6-9343-423f-e5cd-34ee6e256038",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Apr 13 01:19:01 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
            "| N/A   47C    P8             12W /   72W |       0MiB /  23034MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# check GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "editable": true,
        "id": "eZmTzUexsG7e",
        "outputId": "379983a2-c6b1-4a19-8988-539e5481f1fc",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dataclasses_json==0.6.4\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting shutup==0.2.0\n",
            "  Downloading shutup-0.2.0-py3-none-any.whl.metadata (530 bytes)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses_json==0.6.4)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses_json==0.6.4)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses_json==0.6.4) (24.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses_json==0.6.4)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses_json==0.6.4) (4.13.1)\n",
            "Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading shutup-0.2.0-py3-none-any.whl (1.5 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: shutup, mypy-extensions, marshmallow, typing-inspect, dataclasses_json\n",
            "Successfully installed dataclasses_json-0.6.4 marshmallow-3.26.1 mypy-extensions-1.0.0 shutup-0.2.0 typing-inspect-0.9.0\n",
            "Looking in indexes: https://pypi.org/simple, https://abetlen.github.io/llama-cpp-python/whl/cu122\n",
            "Collecting llama-cpp-python==0.3.4\n",
            "  Downloading https://github.com/abetlen/llama-cpp-python/releases/download/v0.3.4-cu122/llama_cpp_python-0.3.4-cp311-cp311-linux_x86_64.whl (445.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m445.2/445.2 MB\u001b[0m \u001b[31m300.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python==0.3.4) (4.13.1)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python==0.3.4) (2.0.2)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python==0.3.4)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python==0.3.4) (3.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.11.3->llama-cpp-python==0.3.4) (3.0.2)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m208.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: diskcache, llama-cpp-python\n",
            "Successfully installed diskcache-5.6.3 llama-cpp-python-0.3.4\n"
          ]
        }
      ],
      "source": [
        "# install packages\n",
        "!pip install dataclasses_json==0.6.4 shutup==0.2.0\n",
        "!pip install --no-cache-dir llama-cpp-python==0.3.4 --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu122"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXR6hQIa5sML",
        "outputId": "90f97548-c953-4c95-99ef-3ee9a602cacb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Ah5uV6cu3Bnz6WfkUuxEZCLqj5k1lbpd\n",
            "To: /content/ML2025Spring-hw2-public.zip\n",
            "100% 621k/621k [00:00<00:00, 131MB/s]\n",
            "Archive:  /content/ML2025Spring-hw2-public.zip\n",
            "   creating: ML2025Spring-hw2-public/\n",
            "  inflating: ML2025Spring-hw2-public/sample_submission.csv  \n",
            "  inflating: ML2025Spring-hw2-public/test.csv  \n",
            "  inflating: ML2025Spring-hw2-public/train.csv  \n"
          ]
        }
      ],
      "source": [
        "# Download dataset\n",
        "!gdown --id 1Ah5uV6cu3Bnz6WfkUuxEZCLqj5k1lbpd\n",
        "# Choose a workable link\n",
        "# !gdown --id 1XtF9-hGw2tKe4WvUMW5YE6lj6p1QcWIc\n",
        "# !gdown --id 1diswE_9XoT-uII23ucRppau1ErEQkY2y\n",
        "# !gdown --id 1BAVMzLZqEgtG8rwog7ttC7xKPw5QTngn\n",
        "# !gdown --id 1PAI4_3kRWwIPQMscMdGt9HLqZZy1vWSD\n",
        "!unzip /content/ML2025Spring-hw2-public.zip\n",
        "# 实验室不能连接外网，所以没有用该方法获取数据集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3uy2PgYe7_T",
        "outputId": "61d6a859-1ff8-4dc1-dc5c-ed9f689ce223"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-13 01:19:28--  https://huggingface.co/bartowski/Qwen2.5-14B-Instruct-1M-GGUF/resolve/main/Qwen2.5-14B-Instruct-1M-Q5_K_S.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.202.34, 13.35.202.97, 13.35.202.40, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.202.34|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/aa/f7/aaf7878389076edd8ae82aabbe3cba7c64452c86e6ad848152e8513d966d62fa/ed5083190ac29b3587f08837063bb9003250e69048ed0c7936401780edb6ed44?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Qwen2.5-14B-Instruct-1M-Q5_K_S.gguf%3B+filename%3D%22Qwen2.5-14B-Instruct-1M-Q5_K_S.gguf%22%3B&Expires=1744510768&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NDUxMDc2OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2FhL2Y3L2FhZjc4NzgzODkwNzZlZGQ4YWU4MmFhYmJlM2NiYTdjNjQ0NTJjODZlNmFkODQ4MTUyZTg1MTNkOTY2ZDYyZmEvZWQ1MDgzMTkwYWMyOWIzNTg3ZjA4ODM3MDYzYmI5MDAzMjUwZTY5MDQ4ZWQwYzc5MzY0MDE3ODBlZGI2ZWQ0ND9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=HTnc1p376rFxccKrdWJy%7EZeO31RDffhA0SurCweDIba7C-jYDyZhVSi5IGpvWNae5ryDq9KqQRtaTyD-Lq0SEBcwh8VhKC7ARNCBdNP67wGpQG2U6ne1Y8h9hQT69dpvZvJcvMD17uwlKDYHyXBBm80%7EyyGWHVPg3Ryoh8gJoTAkBVecFtnTm7FLcjmvCMYVxmkR-1DhbDEjCs68GIAFu8brcWiYLAlX05sPEyk6ea6U9pFOzHYf4jtk1VfZClRec04HFSY4sKf7UpHkIgbr5M4Tv4INUMCNu0rne6djTHncquPRxm4YOXzYgaXZNJuec0TvsJu0JURgHgxYxvCf1Q__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-04-13 01:19:28--  https://cdn-lfs-us-1.hf.co/repos/aa/f7/aaf7878389076edd8ae82aabbe3cba7c64452c86e6ad848152e8513d966d62fa/ed5083190ac29b3587f08837063bb9003250e69048ed0c7936401780edb6ed44?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Qwen2.5-14B-Instruct-1M-Q5_K_S.gguf%3B+filename%3D%22Qwen2.5-14B-Instruct-1M-Q5_K_S.gguf%22%3B&Expires=1744510768&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NDUxMDc2OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2FhL2Y3L2FhZjc4NzgzODkwNzZlZGQ4YWU4MmFhYmJlM2NiYTdjNjQ0NTJjODZlNmFkODQ4MTUyZTg1MTNkOTY2ZDYyZmEvZWQ1MDgzMTkwYWMyOWIzNTg3ZjA4ODM3MDYzYmI5MDAzMjUwZTY5MDQ4ZWQwYzc5MzY0MDE3ODBlZGI2ZWQ0ND9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=HTnc1p376rFxccKrdWJy%7EZeO31RDffhA0SurCweDIba7C-jYDyZhVSi5IGpvWNae5ryDq9KqQRtaTyD-Lq0SEBcwh8VhKC7ARNCBdNP67wGpQG2U6ne1Y8h9hQT69dpvZvJcvMD17uwlKDYHyXBBm80%7EyyGWHVPg3Ryoh8gJoTAkBVecFtnTm7FLcjmvCMYVxmkR-1DhbDEjCs68GIAFu8brcWiYLAlX05sPEyk6ea6U9pFOzHYf4jtk1VfZClRec04HFSY4sKf7UpHkIgbr5M4Tv4INUMCNu0rne6djTHncquPRxm4YOXzYgaXZNJuec0TvsJu0JURgHgxYxvCf1Q__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 108.157.254.4, 108.157.254.110, 108.157.254.125, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|108.157.254.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10266554432 (9.6G) [binary/octet-stream]\n",
            "Saving to: ‘Qwen2.5-14B-Instruct-1M-Q5_K_S.gguf’\n",
            "\n",
            "Instruct-1M-Q5_K_S.  17%[==>                 ]   1.70G   396MB/s    eta 21s    ^C\n"
          ]
        }
      ],
      "source": [
        "# ========================== TODO: try different LLM ==========================\n",
        "# Hugging Face: https://huggingface.co/models?library=gguf\n",
        "# OpenLLM Leaderboard: https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard#/?params=7%2C65&official=true\n",
        "# remember to replace 'blob' with 'resolve' in the link you copy.\n",
        "!wget https://huggingface.co/bartowski/Qwen2.5-14B-Instruct-1M-GGUF/resolve/main/Qwen2.5-14B-Instruct-1M-Q5_K_S.gguf\n",
        "# 实验室不能连接外网，所以没有用该方法获取大模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "editable": true,
        "id": "eG_R1oCjyBV3",
        "outputId": "17e114d8-15d5-41c9-8cc6-6590f310ad09",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA 是否可用: True\n",
            "CUDA 版本: 12.4\n",
            "GPU 数量: 1\n",
            "GPU 0: NVIDIA L4\n",
            "GPU 0 内存总量: 22.16 GB\n",
            "\n",
            "系统信息:\n",
            "Python 版本: 3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0]\n",
            "操作系统: posix\n",
            "\n",
            "llama-cpp-python 信息:\n",
            "Name: llama_cpp_python\n",
            "Version: 0.3.4\n",
            "Summary: Python bindings for the llama.cpp library\n",
            "Home-page: https://github.com/abetlen/llama-cpp-python\n",
            "Author: \n",
            "Author-email: Andrei Betlen <abetlen@gmail.com>\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: diskcache, jinja2, numpy, typing-extensions\n",
            "Required-by: \n",
            "\n",
            "\n",
            "CPU 信息:\n",
            "Architecture:                         x86_64\n",
            "CPU op-mode(s):                       32-bit, 64-bit\n",
            "Address sizes:                        46 bits physical, 48 bits virtual\n",
            "Byte Order:                           Little Endian\n",
            "CPU(s):                               12\n",
            "On-line CPU(s) list:                  0-11\n",
            "Vendor ID:                            GenuineIntel\n",
            "Model name:                           Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "CPU family:                           6\n",
            "Model:                                85\n",
            "Thread(s) per core:                   2\n",
            "Core(s) per socket:                   6\n",
            "Socket(s):                            1\n",
            "Stepping:                             7\n",
            "BogoMIPS:                             4400.32\n",
            "Flags:                                fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat avx512_vnni md_clear arch_capabilities\n",
            "Hypervisor vendor:                    KVM\n",
            "Virtualization type:                  full\n",
            "L1d cache:                            192 KiB (6 instances)\n",
            "L1i cache:                            192 KiB (6 instances)\n",
            "L2 cache:                             6 MiB (6 instances)\n",
            "L3 cache:                             38.5 MiB (1 instance)\n",
            "NUMA node(s):                         1\n",
            "NUMA node0 CPU(s):                    0-11\n",
            "Vulnerability Gather data sampling:   Not affected\n",
            "Vulnerability Itlb multihit:          Not affected\n",
            "Vulnerability L1tf:                   Not affected\n",
            "Vulnerability Mds:                    Not affected\n",
            "Vulnerability Meltdown:               Not affected\n",
            "Vulnerability Mmio stale data:        Vulnerable\n",
            "Vulnerability Reg file data sampling: Not affected\n",
            "Vulnerability Retbleed:               Vulnerable\n",
            "Vulnerability Spec rstack overflow:   Not affected\n",
            "Vulnerability Spec store bypass:      Vulnerable\n",
            "Vulnerability Spectre v1:             Vulnerable: __user pointer sanitization and usercopy barriers only; no swapgs barriers\n",
            "Vulnerability Spectre v2:             Vulnerable; IBPB: disabled; STIBP: disabled; PBRSB-eIBRS: Vulnerable; BHI: Vulnerable (Syscall hardening enabled)\n",
            "Vulnerability Srbds:                  Not affected\n",
            "Vulnerability Tsx async abort:        Vulnerable\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import subprocess\n",
        "\n",
        "# 检查 CUDA 是否可用\n",
        "print(\"CUDA 是否可用:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA 版本:\", torch.version.cuda)\n",
        "    print(\"GPU 数量:\", torch.cuda.device_count())\n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
        "        print(f\"GPU {i} 内存总量: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.2f} GB\")\n",
        "\n",
        "# 检查系统信息\n",
        "print(\"\\n系统信息:\")\n",
        "print(\"Python 版本:\", sys.version)\n",
        "print(\"操作系统:\", os.name)\n",
        "\n",
        "# 尝试检查 llama.cpp 版本或配置\n",
        "try:\n",
        "    result = subprocess.run([\"pip\", \"show\", \"llama-cpp-python\"],\n",
        "                            capture_output=True, text=True)\n",
        "    print(\"\\nllama-cpp-python 信息:\")\n",
        "    print(result.stdout)\n",
        "except Exception as e:\n",
        "    print(\"无法获取 llama-cpp-python 信息:\", e)\n",
        "\n",
        "# 检查 CPU 信息\n",
        "try:\n",
        "    if os.name == 'posix':  # Linux/Mac\n",
        "        cpu_info = subprocess.run([\"lscpu\"], capture_output=True, text=True)\n",
        "        print(\"\\nCPU 信息:\")\n",
        "        print(cpu_info.stdout)\n",
        "    elif os.name == 'nt':  # Windows\n",
        "        cpu_info = subprocess.run([\"wmic\", \"cpu\", \"get\", \"name\"], capture_output=True, text=True)\n",
        "        print(\"\\nCPU 信息:\")\n",
        "        print(cpu_info.stdout)\n",
        "except Exception as e:\n",
        "    print(\"无法获取 CPU 信息:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "editable": true,
        "id": "ZozqjSIgfAuJ",
        "outputId": "50e27053-ce1f-4a82-9045-b30a82ab93e4",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_new_context_with_model: n_ctx_per_seq (10048) < n_ctx_train (1010000) -- the full capacity of the model will not be utilized\n"
          ]
        }
      ],
      "source": [
        "from llama_cpp import Llama\n",
        "\n",
        "# Load the model onto GPU\n",
        "myModel = Llama(\n",
        "    # ========================== TODO: try different LLM ==========================\n",
        "    # Before changing LLM, restart the session!\n",
        "    \"/content/Qwen2.5-14B-Instruct-1M-Q5_K_S.gguf\",\n",
        "    verbose=False,\n",
        "    n_gpu_layers=-1,  # 使用所有可用的 GPU 层\n",
        "    n_ctx=10024,\n",
        "    offload_kqv=True,  # 帮助更好地利用 GPU\n",
        "    n_batch=512       # 增加批处理大小可能提高 GPU 利用率\n",
        ")\n",
        "\n",
        "def generate_response(_model: Llama, _messages: str) -> str:\n",
        "    '''\n",
        "    This function will inference the model with given messages.\n",
        "    '''\n",
        "    _output = _model.create_chat_completion(\n",
        "        _messages,\n",
        "        stop=[\"<|eot_id|>\", \"<|end_of_text|>\"],\n",
        "        max_tokens=8000,    # This argument is how many tokens the model can generate.\n",
        "        temperature=0.2      # This argument is the randomness of the model. 0 means no randomness. We suggest setting the temperature value to 0 for reproducibility.\n",
        "    )[\"choices\"][0][\"message\"][\"content\"]\n",
        "    return _output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": true,
        "id": "gcaXqcVlyBV4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# test_response1 = generate_response(myModel,\"你是一个AI大模型，请给我介绍一下你是谁\")\n",
        "# test_response2 = generate_response(myModel,\"请自我介绍一下,告诉我你是谁\")\n",
        "# test_response3 = generate_response(myModel,\"请自我介绍一下,告诉我你是谁\")\n",
        "# print(test_response1)\n",
        "# print(test_response2)\n",
        "# print(test_response3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgRw-Rt740fF"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jf1drXU_MvAP"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBIdD6RrMuY5"
      },
      "outputs": [],
      "source": [
        "# Define a function to save the best solution and other good solutions to files.\n",
        "def save_run(cfg, journal): #cfg配置对象，journal是来自自定义的 Journal 类的实例\n",
        "    # Retrieve and save the best found solution.\n",
        "    best_node = journal.get_best_node(only_good=False)  # Get the best node.\n",
        "    with open(\"best_solution.py\", \"w\") as f:\n",
        "        f.write(best_node.code)\n",
        "\n",
        "    good_nodes = journal.get_good_nodes()  # Retrieve all good solution nodes.\n",
        "    for i, node in enumerate(good_nodes):\n",
        "        filename = f\"good_solution_{i}.py\"\n",
        "        with open(filename, \"w\") as f:\n",
        "            f.write(node.code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJIf1li3ifQN"
      },
      "source": [
        "### Interpreter (DO NOT MODIFY THIS CELL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gh_v_i3AyBV5",
        "outputId": "71d9e20e-3c47-4132-e660-e08470afbe3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rich in ./anaconda3/envs/mlworks/lib/python3.11/site-packages (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in ./anaconda3/envs/mlworks/lib/python3.11/site-packages (from rich) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./anaconda3/envs/mlworks/lib/python3.11/site-packages (from rich) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in ./anaconda3/envs/mlworks/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n",
            "Requirement already satisfied: humanize in ./anaconda3/envs/mlworks/lib/python3.11/site-packages (4.12.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install rich\n",
        "!pip install humanize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6T1m16_7MCw"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "DO NOT MODIFY THIS CELL\n",
        "\n",
        "Python interpreter for executing code snippets and capturing their output.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import logging\n",
        "import os\n",
        "import queue\n",
        "import signal\n",
        "import sys\n",
        "import time\n",
        "import traceback\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "from shutil import rmtree\n",
        "import shutil\n",
        "from multiprocessing import Process, Queue\n",
        "from typing import Hashable, cast\n",
        "\n",
        "import humanize\n",
        "import rich\n",
        "import shutup\n",
        "from rich.logging import RichHandler\n",
        "from rich.syntax import Syntax\n",
        "from dataclasses import dataclass\n",
        "from dataclasses_json import DataClassJsonMixin\n",
        "\n",
        "\n",
        "@dataclass #Python3.7的装饰器，类似于JS的annotation，可以自动给类添加一些方法来使得这个类具有数据存储的功能\n",
        "class ExecutionResult(DataClassJsonMixin):\n",
        "    \"\"\"\n",
        "    Result of executing a code snippet in the interpreter.\n",
        "    Contains the output, execution time, and exception information.\n",
        "    \"\"\"\n",
        "    term_out: list[str] #模型的输出结果（包括成功的代码或者报错信息）\n",
        "    exec_time: float\n",
        "    exc_type: str | None\n",
        "    exc_info: dict | None = None\n",
        "    exc_stack: list[tuple] | None = None\n",
        "#由于具备装饰器，那么可以直接通过 ER1.term_out 来得到 ER1这个实例的term_out属性值。（否则还要写get_attr的方法）类似地也能更改、比较等\n",
        "\n",
        "def exception_summary(e, exec_file_name):\n",
        "    \"\"\"Generates a string that summarizes an exception and its stack trace\"\"\"\n",
        "    tb_lines = traceback.format_exception(e)\n",
        "    #traceback是来自python的标准类中的方法，这个format_exception方法可以把报错信息以list的类型存储起来\n",
        "    tb_str = \"\".join(\n",
        "        [\n",
        "            line\n",
        "            for line in tb_lines\n",
        "            #把这个list遍历一遍，就组成了报错信息\n",
        "        ]\n",
        "    )\n",
        "    exc_info = {}\n",
        "    if hasattr(e, \"args\"): #e是来自error大类（例如ValueError,TypeError等各类Python的错误类）的某一种实例\n",
        "        exc_info[\"args\"] = [str(i) for i in e.args]  # 这种实例自带很多属性，例如args就是其中一个，它是一个包含了信息的【元组】，和上面的traceback.format_exception有点像，但他是元组\n",
        "    for att in [\"name\", \"msg\", \"obj\"]:\n",
        "        if hasattr(e, att):\n",
        "            exc_info[att] = str(getattr(e, att))\n",
        "    #上面这个for循环是针对自定义错误类型的捕捉，不是python自带错误类型，但是从项目代码来看，项目直接就是使用compile执行了LLM生成的代码，所以到底哪里来的自定义错误呢？\n",
        "    #或许是llama？待查证。\n",
        "    #对于python的错误类型，只有比较简略的元组数据返回，例如错误\n",
        "    \"\"\"\n",
        "    Traceback (most recent call last):\n",
        "  File c:\\\\Users\\\\Administrator\\\\理解 exception_summary.py\", line 70, in test_standard_exceptions\n",
        "    print(my_list[10])\n",
        "          ~~~~~~~^^^^\n",
        "    IndexError: list index out of range\n",
        "    \"\"\"\n",
        "    #对于这个错误的，就有元组:{'args': ['list index out of range']}\n",
        "    #如果想让LLM帮我们改错误，这种程度的错误肯定是不够的，所以我们引入了自定义的错误类型，也就是用\"name\", \"msg\", \"obj\"更加详细地说明了错误\n",
        "    #详见参考代码：理解 exception_summary.py\n",
        "\n",
        "    tb = traceback.extract_tb(e.__traceback__)  # Extract the traceback information.\n",
        "    # Create a list of tuples for each frame in the traceback.\n",
        "    exc_stack = [(t.filename, t.lineno, t.name, t.line) for t in tb]\n",
        "\n",
        "    return tb_str, e.__class__.__name__, exc_info, exc_stack  #总之最后是返回了一个具备完整报错信息和报错信息各个分类属性的信息，需要继续看一下到底是怎么定义这个e的。\n",
        "\n",
        "# Define a class that redirects write operations to a multiprocessing queue.\n",
        "class RedirectQueue:\n",
        "    def __init__(self, queue, timeout=5):\n",
        "        self.queue = queue  # Store the provided queue.\n",
        "        self.timeout = timeout  # Set the timeout for queue operations.\n",
        "\n",
        "    def write(self, msg):\n",
        "        try:\n",
        "            self.queue.put(msg, timeout=self.timeout)  # Attempt to put the message into the queue.\n",
        "        except queue.Full:\n",
        "            print.warning(\"Queue write timed out\")  # Warn if the queue is full and the write times out.\n",
        "\n",
        "    def flush(self):\n",
        "        pass  # No operation is needed for flushing in this context.\n",
        "        #这是一个用于捕获多进程环境下错误信息的类，是结合 Python的 multiprocessing 模块使用的\n",
        "        #简单来说，他是捕获 Queue 类（来自multiprocessing模块）的信息的，这个信息来自 Process 类（来自multiprocessing模块）\n",
        "        #详见示例代码 理解Queue.py\n",
        "\n",
        "# Define the Interpreter class that simulates a standalone Python REPL.\n",
        "class Interpreter: #执行LLM生成的代码\n",
        "    def __init__(\n",
        "        self,\n",
        "        timeout: int = 1200,  # 程序（子进程）的执行总时长，超过此时长的程序将直接被切断\n",
        "        agent_file_name: str = \"runfile.py\",  # Default file name for writing the agent's code.\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Simulates a standalone Python REPL with an execution time limit.\n",
        "\n",
        "        Args:\n",
        "            timeout (int, optional): Timeout for each code execution step. Defaults to 3600.\n",
        "            agent_file_name (str, optional): The name for the agent's code file. Defaults to \"runfile.py\".\n",
        "        \"\"\"\n",
        "        self.timeout = timeout  # Save the timeout value.\n",
        "        self.agent_file_name = agent_file_name  # Save the agent file name.\n",
        "        self.process: Process = None  # 来自 Process 类的实例process（来自multiprocessing模块）\n",
        "\n",
        "    def child_proc_setup(self, result_outq: Queue) -> None:\n",
        "        import shutup\n",
        "        shutup.mute_warnings()  # Mute all warnings before further execution.\n",
        "        sys.stdout = sys.stderr = RedirectQueue(result_outq)\n",
        "        #函数的作用是把 sys.stdout 和 sys.stderr 直接传给RedirectQueue\n",
        "        #这个连等相当于:\n",
        "        #temp =  RedirectQueue(result_outq)\n",
        "        #sys.stderr = temp\n",
        "        #sys.stdout = temp\n",
        "        #目的就是把程序的所有输出（包括错误）传给RedirectQueue，便于LLM进行下一步的分析\n",
        "        #shutup.mute_warnings()则是不想警告信息进来干扰执行，\n",
        "        #如果你用过LLM你就知道LLM为了力求全面，很多时候都会对警告信息尝试性修复，但是这种修复很多时候都是没用的。\n",
        "\n",
        "    def _run_session(\n",
        "        self, code_inq: Queue, result_outq: Queue, event_outq: Queue\n",
        "    ) -> None:\n",
        "        self.child_proc_setup(result_outq)  # Set up the child process for capturing output.\n",
        "        #创建子进程，使LLM生成的代码独立于main之外，出现了错误的代码也不会中断main\n",
        "        global_scope: dict = {}  # Create an empty dictionary to serve as the global scope.\n",
        "        while True:  # Continuously wait for new code to execute.\n",
        "            code = code_inq.get()  # Retrieve code from the code input queue.\n",
        "            with open(self.agent_file_name, \"w\") as f:  # Open the agent file for writing.\n",
        "                f.write(code)  # Write the received code into the file.\n",
        "            #这里为什么要写进一个文件是为了报错的时候知道具体是哪一行报错了，否则悬空放置的话不知道如何改错\n",
        "            event_outq.put((\"state:ready\",))  # Signal that the interpreter is ready to execute the code.\n",
        "            try:\n",
        "                #这里直接调用了python自带的执行(exec)和编译(compile)来运行程序，那么上面说的自定义错误从何而来？\n",
        "                exec(compile(code, self.agent_file_name, \"exec\"), global_scope)\n",
        "                #一旦上面的try失败（也就是程序出错了），那么就开始使用exception_summary捕捉这个程序的错误\n",
        "            except BaseException as e:\n",
        "                tb_str, e_cls_name, exc_info, exc_stack = exception_summary(\n",
        "                    e,\n",
        "                    self.agent_file_name,\n",
        "                )\n",
        "                result_outq.put(tb_str)  # Put the traceback string into the result queue.\n",
        "                if e_cls_name == \"KeyboardInterrupt\":\n",
        "                    e_cls_name = \"TimeoutError\"  # Convert a KeyboardInterrupt into a TimeoutError.\n",
        "                event_outq.put((\"state:finished\", e_cls_name, exc_info, exc_stack))  # Signal that execution finished with an error.\n",
        "            else:\n",
        "                event_outq.put((\"state:finished\", None, None, None))  # Signal that execution finished successfully.\n",
        "\n",
        "            os.remove(self.agent_file_name)  # Remove the agent file after execution.\n",
        "\n",
        "            result_outq.put(\"<|EOF|>\")  # Put an EOF marker to indicate the end of output.\n",
        "\n",
        "    def create_process(self) -> None:\n",
        "        # Create three queues for communication with the child process:\n",
        "        # - code_inq: for sending code to execute.\n",
        "        # - result_outq: for receiving output from the execution.\n",
        "        # - event_outq: for receiving state events (like ready and finished).\n",
        "        # trunk-ignore(mypy/var-annotated)\n",
        "        self.code_inq, self.result_outq, self.event_outq = Queue(), Queue(), Queue()\n",
        "        #多线程处理中，Queue用于存放信息\n",
        "        self.process = Process(\n",
        "            target=self._run_session,  # Set the target function for the child process.\n",
        "            args=(self.code_inq, self.result_outq, self.event_outq),  # Provide the necessary queues as arguments.\n",
        "        )\n",
        "        self.process.start()  # Start the child process.\n",
        "        #开始利用 process 实例来执行程序\n",
        "\n",
        "    def cleanup_session(self):\n",
        "        if self.process is None:  # If there is no process, nothing to clean up.\n",
        "            return\n",
        "        try:\n",
        "            # Attempt to terminate the child process gracefully.\n",
        "            self.process.terminate()  # Request the process to terminate.\n",
        "            self.process.join(timeout=0.5)  # Wait for the process to finish with a 0.5-second timeout.\n",
        "\n",
        "            if self.process.exitcode is None:  # If the process is still running,\n",
        "                self.process.kill()  # Forcefully kill the process.\n",
        "                self.process.join(timeout=0.5)  # Wait again for termination.\n",
        "\n",
        "                if self.process.exitcode is None:  # If the process still hasn't terminated,\n",
        "                    os.kill(self.process.pid, signal.SIGKILL)  # Send a SIGKILL signal.\n",
        "        except Exception as e:\n",
        "            print(f\"Error during process cleanup: {e}\")  # Print an error message if cleanup fails.\n",
        "        finally:\n",
        "            if self.process is not None:  # If the process exists,\n",
        "                self.process.close()  # Close the process.\n",
        "                self.process = None  # Reset the process attribute to None.\n",
        "        # 清理队列，确保没有残留数据\n",
        "        if hasattr(self, \"code_inq\"):\n",
        "            self.code_inq.close()\n",
        "        if hasattr(self, \"result_outq\"):\n",
        "            self.result_outq.close()\n",
        "        if hasattr(self, \"event_outq\"):\n",
        "            self.event_outq.close()\n",
        "\n",
        "    def run(self, code: str, reset_session=True) -> ExecutionResult:\n",
        "        \"\"\"\n",
        "        Execute the provided Python command in a separate process and return its output.\n",
        "\n",
        "        Parameters:\n",
        "            code (str): Python code to execute.\n",
        "            reset_session (bool, optional): Whether to reset the interpreter session before executing the code. Defaults to True.\n",
        "\n",
        "        Returns:\n",
        "            ExecutionResult: Object containing the output and metadata of the code execution.\n",
        "        \"\"\"\n",
        "\n",
        "        if reset_session:\n",
        "            if self.process is not None:\n",
        "                # If a previous process exists, clean it up before starting a new one.\n",
        "                self.cleanup_session()\n",
        "            self.create_process()  # Create a new child process.\n",
        "        else:\n",
        "            # For the first execution, reset_session must be True.\n",
        "            assert self.process is not None\n",
        "\n",
        "        assert self.process.is_alive()  # Ensure that the child process is running.\n",
        "\n",
        "        self.code_inq.put(code)  # Send the code to the child process via the queue.\n",
        "        #进程是空的的时候才把LLM的code进行执行\n",
        "        # Wait for the child process to signal that it is ready.\n",
        "        try:\n",
        "            state = self.event_outq.get(timeout=10)  # Wait up to 10 seconds for the \"state:ready\" event.\n",
        "        except queue.Empty:\n",
        "            msg = \"REPL child process failed to start execution\"\n",
        "            print.critical(msg)  # Log a critical error if the process does not start.\n",
        "            while not self.result_outq.empty():\n",
        "                continue  # Drain the result queue.\n",
        "            raise RuntimeError(msg) from None\n",
        "        assert state[0] == \"state:ready\", state  # Verify that the received state is \"state:ready\".\n",
        "        start_time = time.time()  # Record the start time of execution.\n",
        "\n",
        "        child_in_overtime = False  # Flag to indicate if the child process has exceeded the timeout.\n",
        "\n",
        "        while True:\n",
        "            try:\n",
        "                # Try to get the finished state from the child process.\n",
        "                state = self.event_outq.get(timeout=1)  # Wait for the \"state:finished\" event.\n",
        "                assert state[0] == \"state:finished\", state  # Ensure the state is \"state:finished\".\n",
        "                exec_time = time.time() - start_time  # Calculate the total execution time.\n",
        "                break  # Exit the loop if execution is finished.\n",
        "            except queue.Empty:\n",
        "                # If no event is received, check whether the process is still alive.\n",
        "                if not child_in_overtime and not self.process.is_alive():\n",
        "                    msg = \"REPL child process died unexpectedly\"\n",
        "                    raise RuntimeError(msg) from None\n",
        "\n",
        "                # If the process is still running, check if it has exceeded the timeout.\n",
        "                if self.timeout is None:\n",
        "                    continue\n",
        "                running_time = time.time() - start_time  # Determine the running time.\n",
        "                if running_time > self.timeout:\n",
        "                    print(f\"Execution exceeded timeout of {self.timeout}s\")  # Log a timeout message.\n",
        "                    os.kill(self.process.pid, signal.SIGINT)  # Send SIGINT to the process.\n",
        "                    child_in_overtime = True  # Mark that the process is now in overtime.\n",
        "\n",
        "                    # If the process exceeds the timeout by more than 5 seconds, force cleanup.\n",
        "                    if running_time > self.timeout + 5:\n",
        "                        self.cleanup_session()  # Clean up the child process.\n",
        "\n",
        "                        state = (None, \"TimeoutError\", {}, [])  # Set state to indicate a timeout error.\n",
        "                        exec_time = self.timeout  # Set the execution time to the timeout limit.\n",
        "                        break\n",
        "\n",
        "        output: list[str] = []  # Initialize a list to collect output lines.\n",
        "        # Collect all output from the result queue until the EOF marker is encountered.\n",
        "        start_collect = time.time()  # Record the start time for output collection.\n",
        "        while not self.result_outq.empty() or not output or output[-1] != \"<|EOF|>\":\n",
        "            try:\n",
        "                # If output collection exceeds 5 seconds, log a warning.\n",
        "                if time.time() - start_collect > 5:\n",
        "                    print.warning(\"Output collection timed out\")\n",
        "                    break\n",
        "                output.append(self.result_outq.get(timeout=1))  # Append the next line of output.\n",
        "            except queue.Empty:\n",
        "                continue  # Continue if no output is available immediately.\n",
        "        output.pop()  # Remove the EOF marker from the output list.\n",
        "\n",
        "        # Extract exception information from the finished state.\n",
        "        e_cls_name, exc_info, exc_stack = state[1:]\n",
        "\n",
        "        if e_cls_name == \"TimeoutError\":\n",
        "            # Append a timeout error message to the output if a timeout occurred.\n",
        "            output.append(\n",
        "                f\"TimeoutError: Execution exceeded the time limit of {humanize.naturaldelta(self.timeout)}\"\n",
        "            )\n",
        "        else:\n",
        "            # Append the execution time information to the output.\n",
        "            output.append(\n",
        "                f\"Execution time: {humanize.naturaldelta(exec_time)} seconds (time limit is {humanize.naturaldelta(self.timeout)}).\"\n",
        "            )\n",
        "        # Return an ExecutionResult object with all the execution details.\n",
        "        return ExecutionResult(output, exec_time, e_cls_name, exc_info, exc_stack)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJy6O6WpnQCM"
      },
      "source": [
        "### Nodes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ef9JvWJr7Xvg"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import uuid\n",
        "from dataclasses import dataclass, field\n",
        "#注意，这里引入了一个名为 field 的数据类\n",
        "from typing import Literal, Optional\n",
        "from dataclasses_json import DataClassJsonMixin\n",
        "\n",
        "\n",
        "@dataclass(eq=False) #禁用了数据类型之间相等的比较关系\n",
        "class Node(DataClassJsonMixin):\n",
        "    \"\"\"A single node in the solution tree. Contains code, execution results, and evaluation information.\"\"\"\n",
        "    # field 方法提供了更加精细化的属性控制\n",
        "    # 例如下面的属性中基本都有 kw_only=True 这一词缀，这说明在初始化该属性时必须具备关键词(key word)，而不能使用位置对应的方式来访问该属性\n",
        "    # 被 field 修饰的这种特殊的属性，也叫做“字段”，下面将这些具备field特性的属性称为字段。\n",
        "    # ---- code & plan ----\n",
        "    code: str\n",
        "    plan: str = field(default=None, kw_only=True)  # type: ignore\n",
        "    #plan的默认值是 None，调用该属性时必须声明其名字 plan,一个例子如下\n",
        "    \"\"\"\n",
        "    正确用法\n",
        "    node = Node(code=\"print('hello')\", plan=\"My plan\")\n",
        "    错误用法\n",
        "    node = Node(\"print('hello')\", \"My plan\")\n",
        "                                   ^^^这会报错\n",
        "    \"\"\"\n",
        "    # ---- general attrs ----\n",
        "    step: int = field(default=None, kw_only=True)  # type: ignore\n",
        "    id: str = field(default_factory=lambda: uuid.uuid4().hex, kw_only=True)\n",
        "    #这里展示了field的另外一个能力：为字段赋予一个方法。\n",
        "    #uuid.uuid4().hex是一个生成随机数的方法\n",
        "    #同时还要注意这里用的是default_factory，而不是default，这是为了每个实例创建的时候都有一个不同的值。\n",
        "    #如果是default，那么每个实例的id字段全是相同的值\n",
        "    ctime: float = field(default_factory=lambda: time.time(), kw_only=True)\n",
        "    parent: Optional[\"Node\"] = field(default=None, kw_only=True)\n",
        "    #Optional意味着这字段可以是Node对象，也可以是None\n",
        "    children: set[\"Node\"] = field(default_factory=set, kw_only=True)\n",
        "    #set的特性：无序与不可重复\n",
        "    \"\"\"\n",
        "    上面这个关于父节点和子节点配置的设置是非常实用的设计思想。\n",
        "    除去Optional和set设置对父节点和子节点特性的高度抽象概括，这里还引入了forward reference，也就是我们看到的使用字符串 “Node” 预先引用了Node类。\n",
        "    这样可以避免在Node还没生成完毕时引用Node而产生的错误。\n",
        "    这套设计生成了树状结构，在各种算法设计中，这是非常实用的操作。\n",
        "    \"\"\"\n",
        "    # ---- execution info ----\n",
        "    _term_out: list[str] = field(default=None, kw_only=True)  # type: ignore\n",
        "    exec_time: float = field(default=None, kw_only=True)  # type: ignore\n",
        "    exc_type: str | None = field(default=None, kw_only=True)\n",
        "    # str | None 等价于 Optional[str]，当执行没有错误的时候，这个字段就是None。同时要注意这个特性是Py3.10+的，所以该项目的py版本>=10\n",
        "    exc_info: dict | None = field(default=None, kw_only=True)\n",
        "    exc_stack: list[tuple] | None = field(default=None, kw_only=True)\n",
        "\n",
        "    # ---- evaluation ----\n",
        "    # post-execution result analysis (findings/feedback)\n",
        "    analysis: str = field(default=None, kw_only=True)  # type: ignore\n",
        "    metric: float = field(default=None, kw_only=True)  # type: ignore\n",
        "    # whether the agent decided that the code is buggy\n",
        "    # -> always True if exc_type is not None or no valid metric\n",
        "    is_buggy: bool = field(default=None, kw_only=True)  # type: ignore\n",
        "    improve_flag: bool = field(default=None, kw_only=False)\n",
        "\n",
        "    def __post_init__(self) -> None:\n",
        "        if self.parent is not None:\n",
        "            self.parent.children.add(self)\n",
        "\n",
        "    @property\n",
        "    def stage_name(self) -> Literal[\"draft\", \"debug\", \"improve\"]:\n",
        "        \"\"\"\n",
        "        Return the stage of the node:\n",
        "        - \"stage\" if the node is an initial solution draft\n",
        "        - \"debug\" if the node is the result of a debugging step\n",
        "        - \"improve\" if the node is the result of an improvement step\n",
        "        \"\"\"\n",
        "        if self.parent is None:\n",
        "            return \"draft\"\n",
        "        #不存在父节点时，该node处于draft stage(草稿阶段）\n",
        "        return \"debug\" if self.parent.is_buggy else \"improve\"\n",
        "        #父节点出错时，该节点进入 debug stage，否则进入improve stage\n",
        "        # property装饰器可以让我们直接通过像属性一样访问方法\n",
        "        #具体来说，就是 node.stage_name 就可以直接访问到这个方法了，而不需要 node.stage_name()\n",
        "\n",
        "\n",
        "    def absorb_exec_result(self, exec_result: ExecutionResult):\n",
        "        \"\"\"Absorb the result of executing the code from this node.\"\"\"\n",
        "        self._term_out = exec_result.term_out\n",
        "        self.exec_time = exec_result.exec_time\n",
        "        self.exc_type = exec_result.exc_type\n",
        "        self.exc_info = exec_result.exc_info\n",
        "        self.exc_stack = exec_result.exc_stack\n",
        "\n",
        "    @property\n",
        "    def term_out(self) -> str:\n",
        "        \"\"\"Get the terminal output of the code execution (after truncating it).\"\"\"\n",
        "        return trim_long_string(\"\".join(self._term_out))\n",
        "\n",
        "    @property\n",
        "    def is_leaf(self) -> bool:\n",
        "        \"\"\"Check if the node is a leaf node in the solution tree.\"\"\"\n",
        "        return not self.children\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        return isinstance(other, Node) and self.id == other.id\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash(self.id)\n",
        "\n",
        "    @property\n",
        "    def debug_depth(self) -> int:\n",
        "        \"\"\"\n",
        "        Length of the current debug path\n",
        "        - 0 if the node is not a debug node (parent is not buggy)\n",
        "        - 1 if the parent is buggy but the skip parent isn't\n",
        "        - n if there were n consecutive debugging steps\n",
        "        \"\"\"\n",
        "        if self.stage_name != \"debug\":\n",
        "            return 0\n",
        "        return self.parent.debug_depth + 1  # type: ignore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr5hZPyKnO8y"
      },
      "source": [
        "### Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdIKQ-ZHnQmY"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Journal(DataClassJsonMixin):\n",
        "    \"\"\"节点串起来，形成了“树”\"\"\"\n",
        "\n",
        "    nodes: list[Node] = field(default_factory=list)\n",
        "    #变量名: 类型 = 值，类似函数的注解，这是对变量的注解。\n",
        "    #这里再次调用了default_factory也是一样的原因，避免所有journal的nodes都相同。\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Node:\n",
        "        return self.nodes[idx]\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"Return the number of nodes in the journal.\"\"\"\n",
        "        return len(self.nodes)\n",
        "\n",
        "    def append(self, node: Node) -> None:\n",
        "        \"\"\"Append a new node to the journal.\"\"\"\n",
        "        node.step = len(self.nodes)\n",
        "        self.nodes.append(node)\n",
        "\n",
        "    @property\n",
        "    def draft_nodes(self) -> list[Node]:\n",
        "        \"\"\"Return a list of nodes representing intial coding drafts\"\"\"\n",
        "        return [n for n in self.nodes if n.parent is None]\n",
        "        #经典的列表推导式\n",
        "        \"\"\"\n",
        "        第一个n代表即将放入这个列表的内容，为什么我知道是列表，是因为最外侧的两个[]\n",
        "        第二个n就是循环变量，当然这个循环变量最后是要放入列表的\n",
        "        在哪里循环？在node.parent=None的地方循环\n",
        "        也就是把所有没有父节点的Node视为draft.\n",
        "        \"\"\"\n",
        "\n",
        "    @property\n",
        "    def buggy_nodes(self) -> list[Node]:\n",
        "        \"\"\"Return a list of nodes that are considered buggy by the agent.\"\"\"\n",
        "        return [n for n in self.nodes if n.is_buggy]\n",
        "\n",
        "    @property\n",
        "    def good_nodes(self) -> list[Node]:\n",
        "        \"\"\"Return a list of nodes that are not considered buggy by the agent.\"\"\"\n",
        "        return [n for n in self.nodes if not n.is_buggy]\n",
        "\n",
        "    def get_metric_history(self) -> list[float]:\n",
        "        \"\"\"Return a list of all metric values in the journal.\"\"\"\n",
        "        return [n.metric for n in self.nodes]\n",
        "\n",
        "    def get_good_nodes(self) -> Node:\n",
        "        return [n for n in self.nodes if not n.is_buggy]\n",
        "        #good nodes 的定义就是没有出BUG的节点\n",
        "\n",
        "    def get_best_node(self, only_good=True) -> None | Node:\n",
        "        \"\"\"Return the best solution found so far (node with the highest validation metric).\"\"\"\n",
        "        if only_good:\n",
        "            nodes = self.good_nodes\n",
        "            if not nodes:\n",
        "                return None\n",
        "        else:\n",
        "            nodes = self.nodes\n",
        "        return min(nodes, key=lambda n: n.metric)\n",
        "\n",
        "    def generate_summary(self, include_code: bool = False) -> str:\n",
        "        \"\"\"Generate a summary of the journal for the agent.\"\"\"\n",
        "        summary = []\n",
        "        for n in self.good_nodes:\n",
        "            summary_part = f\"Design: {n.plan}\\n\"\n",
        "            if include_code:\n",
        "                summary_part += f\"Code: {n.code}\\n\"\n",
        "            summary_part += f\"Results: {n.analysis}\\n\"\n",
        "            summary_part += f\"Validation Metric (Mean Squared Error): {n.metric}\\n\"\n",
        "            summary.append(summary_part)\n",
        "        return \"\\n-------------------------------\\n\".join(summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHofZDRkfCBg"
      },
      "source": [
        "### Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiz_KLQnyBV6",
        "outputId": "02392a13-f84f-4ad9-bd91-59a1b9280dfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydantic in ./anaconda3/envs/mlworks/lib/python3.11/site-packages (2.10.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./anaconda3/envs/mlworks/lib/python3.11/site-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in ./anaconda3/envs/mlworks/lib/python3.11/site-packages (from pydantic) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in ./anaconda3/envs/mlworks/lib/python3.11/site-packages (from pydantic) (4.12.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pydantic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Sg4cBTy7JIO"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from typing import Any, Callable, cast\n",
        "\n",
        "import re\n",
        "import sys\n",
        "import json\n",
        "import humanize\n",
        "\n",
        "from pydantic import BaseModel\n",
        "\n",
        "\n",
        "ExecCallbackType = Callable[[str, bool], ExecutionResult]\n",
        "\n",
        "\n",
        "class Agent:\n",
        "    def __init__(\n",
        "        self,\n",
        "        cfg,\n",
        "        journal: Journal,\n",
        "        #Agent类的参数列表\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.journal = journal\n",
        "        self.data_preview: str | None = None\n",
        "        #给参数列表赋值\n",
        "\n",
        "    def search_policy(self) -> Node | None:\n",
        "        \"\"\"Select a node to work on (or None to draft a new node).\"\"\"\n",
        "        search_cfg = self.cfg.agent.search\n",
        "\n",
        "        # initial drafting\n",
        "        if len(self.journal.draft_nodes) < search_cfg.num_drafts:\n",
        "            return None\n",
        "            #如果 draft_nodes(记得吗？之前这里是一个列表推导式）的长度，即draft node的个数小于设定值\n",
        "            #那么返回None\n",
        "            #在step函数中，search_policy = None 会把当前Node设置为 draft node.\n",
        "\n",
        "        # debugging\n",
        "        if random.random() < search_cfg.debug_prob:\n",
        "            # nodes that are buggy + leaf nodes + debug depth < max debug depth\n",
        "            debuggable_nodes = [\n",
        "                n\n",
        "                for n in self.journal.buggy_nodes\n",
        "                if n.is_leaf\n",
        "            ]\n",
        "            #只从叶节点中挑buggy节点\n",
        "            #一般而言LLM生成的第一版代码都没啥问题，可能只是在考虑改进的时候会发生一些问题。\n",
        "            if debuggable_nodes:\n",
        "                return random.choice(debuggable_nodes)\n",
        "            #非常有趣的一点是，这里居然是依靠概率来决定是否进行调试的，而不是根据程序是否出现BUG\n",
        "            #我个人的猜想：不是所有的BUG都值得修复，也许新创建一个算法更值得尝试\n",
        "            #如果程序死磕在一个BUG上，资源都被浪费了\n",
        "            #这种设计或许是能够提高程序产出高品质代码的一种考虑\n",
        "\n",
        "\n",
        "        # back to drafting if no nodes to improve\n",
        "        good_nodes = self.journal.good_nodes\n",
        "        if not good_nodes:\n",
        "            return None\n",
        "\n",
        "        # greedy\n",
        "        greedy_node = self.journal.get_best_node()\n",
        "\n",
        "        return greedy_node\n",
        "\n",
        "\n",
        "    def plan_and_code_query(self, system_message, user_message, retries=3) -> tuple[str, str]:\n",
        "        \"\"\"\n",
        "        Generate a natural language plan + code in the same LLM call and split them apart.\n",
        "        注：这是一个统一的输入接口，不同的agent最终都会把信息输入到这个接口上来，这个接口再与本地的LLM进行交互，输出结果\n",
        "        \"\"\"\n",
        "        completion_text = None\n",
        "        for _ in range(retries):\n",
        "            response = generate_response(\n",
        "                myModel,\n",
        "                _messages=[\n",
        "                    {'role': 'system', \"content\": system_message},\n",
        "                    {'role': 'user', \"content\": user_message}\n",
        "                ]\n",
        "            )\n",
        "            completion_text = response\n",
        "            code = extract_code(completion_text)\n",
        "            nl_text = extract_text_up_to_code(completion_text)\n",
        "            #这里还对输出进行了一点处理，也就是将其分成了代码块部分和自然语言部分，实现在下面的 text processing 部分\n",
        "            if code:\n",
        "                return nl_text, code\n",
        "            print(\"Plan + code extraction failed, retrying...\")\n",
        "        print(\"Final plan + code extraction attempt failed, giving up...\")\n",
        "        return \"\", completion_text\n",
        "\n",
        "    def _draft(self) -> Node:\n",
        "        # ================ TODO: ask LLM agents to come up with a solution and then implement ================\n",
        "        system_prompt = \"你是一个提出机器学习相关解决方案的机器人\"\n",
        "        user_prompt = [ #可以尝试着注释掉这个部分\n",
        "            \"你必须针对下列任务提出一个优秀的机器学习解决方案，该机器学习必须以python的形式实现\"\n",
        "            f\"任务是{str(self.cfg.task_goal)} \",\n",
        "            f'所有的数据在路径\"{self.cfg.data_dir}\"下',\n",
        "            f\"{str(self.data_preview)}\",\n",
        "            '你必须把对test集的预测结果放在目录\"/content/submissionRes.csv\"下.',\n",
        "            \"Note that the testing file DOES NOT have the target column.\"\n",
        "        ]\n",
        "        system_message = system_prompt\n",
        "        user_message = \"\\n\".join(user_prompt)\n",
        "        plan, code = self.plan_and_code_query(system_message=system_message, user_message=user_message)\n",
        "        return Node(plan=plan, code=code)\n",
        "\n",
        "    def _improve(self, parent_node: Node) -> Node:\n",
        "\n",
        "        # ================  TODO: ask LLM agent to improve drafts ================\n",
        "\n",
        "        system_prompt = \"你是一个专门优化代码性能的的人工智能\"\n",
        "\n",
        "        user_prompt = [\n",
        "            f\"任务描述: {str(self.cfg.task_goal)} \"\n",
        "            f\"这是已有的记忆: {str(self.journal.generate_summary())} \"\n",
        "            f\"待优化的代码 {str(wrap_code(parent_node.code))} \"\n",
        "        ]\n",
        "        system_message = system_prompt\n",
        "        user_message = \" \".join(user_prompt)\n",
        "        plan, code = self.plan_and_code_query(system_message=system_message, user_message=user_message)\n",
        "        return Node(plan=plan, code=code, parent=parent_node, improve_flag=True)\n",
        "\n",
        "    def _debug(self, parent_node: Node) -> Node:\n",
        "\n",
        "        # ================  TODO: ask LLM agent to debug ================\n",
        "        system_prompt = \"你是一个用于解决代码BUG的人工智能\"\n",
        "\n",
        "\n",
        "        user_prompt = [\n",
        "            f\"任务描述: {str(self.cfg.task_goal)}\\n\\n\",\n",
        "            f\"之前的错误代码是: {str(wrap_code(parent_node.code))}\\n\\n\",\n",
        "            f\"代码的处理结果是: {str(wrap_code(parent_node.term_out, lang=''))}\\n\\n\",\n",
        "            str(self.data_preview)\n",
        "        ]\n",
        "\n",
        "        system_message = system_prompt\n",
        "        user_message = \" \".join(user_prompt)\n",
        "\n",
        "        plan, code = self.plan_and_code_query(system_message=system_message, user_message=user_message)\n",
        "        return Node(plan=plan, code=code, parent=parent_node)\n",
        "\n",
        "    def update_data_preview(\n",
        "        self,\n",
        "    ):\n",
        "        self.data_preview = data_preview_generate(cfg.data_dir)\n",
        "\n",
        "    def step(self, exec_callback: ExecCallbackType):\n",
        "    # 执行一个步骤，选择合适的节点进行 draft、debug 或 improve 操作。\n",
        "    # 如果没有节点或数据预览为空，则生成数据预览\n",
        "        if not self.journal.nodes or self.data_preview is None:\n",
        "            self.update_data_preview()\n",
        "\n",
        "        # 根据搜索策略选择父节点\n",
        "        parent_node = self.search_policy()\n",
        "\n",
        "        # 如果没有父节点，则创建一个草稿节点\n",
        "        if parent_node is None:\n",
        "            result_node = self._draft()\n",
        "\n",
        "        # 如果父节点有 bug，则进行 debug 操作\n",
        "        elif parent_node.is_buggy:\n",
        "            result_node = self._debug(parent_node)\n",
        "\n",
        "        # 如果父节点没有 bug 且尚未被改进，则进行 improve 操作\n",
        "        elif not parent_node.improve_flag:\n",
        "            result_node = self._improve(parent_node)\n",
        "\n",
        "        # 如果父节点已经被改进过，则跳过\n",
        "        else:\n",
        "            print(f\"Node {parent_node} 已经被改进过，跳过此节点。\")\n",
        "            return\n",
        "\n",
        "        # 解析执行结果并将结果节点添加到日志中\n",
        "        self.parse_exec_result(\n",
        "            node=result_node,\n",
        "            exec_result=exec_callback(result_node.code, True),\n",
        "        )\n",
        "        self.journal.append(result_node)\n",
        "\n",
        "\n",
        "    # def step(self, exec_callback: ExecCallbackType):\n",
        "    #     #Agent.step 是决定程序运行步数的关键参数，它决定了调用几次agent\n",
        "    #     if not self.journal.nodes or self.data_preview is None:\n",
        "    #         #case:1 如果不存在节点或者不存在 data_preview, 那么先生成一个数据preview\n",
        "    #         self.update_data_preview()\n",
        "\n",
        "    #     parent_node = self.search_policy()\n",
        "    #     #现在有节点了，开始进行搜索策略\n",
        "    #     if parent_node is None:\n",
        "    #         result_node = self._draft()\n",
        "    #         #节点没有父节点，那么节点就是草稿节点\n",
        "    #     elif parent_node.is_buggy:\n",
        "    #         result_node = self._debug(parent_node)\n",
        "    #         #节点有bug，那么节点需要进行debug操作\n",
        "    #     else:\n",
        "    #         result_node = self._improve(parent_node)\n",
        "    #         #如果节点有父节点，并且还有没BUG，那么进行improve操作\n",
        "    #     self.parse_exec_result(\n",
        "    #         #将节点类别分类完后，送到代码运行结果评估agent\n",
        "    #         node=result_node,\n",
        "    #         exec_result=exec_callback(result_node.code, True),\n",
        "    #     )\n",
        "    #     self.journal.append(result_node)\n",
        "\n",
        "\n",
        "    def parse_exec_result(self, node: Node, exec_result: ExecutionResult):\n",
        "        node.absorb_exec_result(exec_result)\n",
        "        system_prompt = \"\"\"\n",
        "                你是一个评估机器学习成果的人工智能。\n",
        "                请分析代码执行结果，并以JSON格式返回以下信息：\n",
        "                1. summary: 对代码执行结果的简要分析\n",
        "                2. is_buggy: 代码是否存在bug (true/false)\n",
        "                3. metric: 如果有性能指标，请提取数值(如MSE等)；如果没有有效的MSE，则设置MSE=3.0\n",
        "\n",
        "                你的回答必须是一个有效的JSON对象，格式如下:\n",
        "                {\n",
        "                    \"summary\": \"...\",\n",
        "                    \"is_buggy\": true/false,\n",
        "                    \"metric\": 正确数值或3.0\n",
        "                }\n",
        "                \"\"\"\n",
        "        # ================  TODO: ask LLM agent to extract evaluation result from the execution output. ================\n",
        "        # save log file\n",
        "        user_prompt = f\"\"\"\n",
        "            任务描述是:\n",
        "            {self.cfg.task_goal}\n",
        "            代码实现是:\n",
        "            {wrap_code(node.code)}\n",
        "            代码的输出结果是:\n",
        "            {wrap_code(node.term_out, lang=\"\")}\n",
        "        \"\"\"\n",
        "        print(\"传入parse_exer_result的执行结果是:\",node.term_out)\n",
        "        system_message = system_prompt\n",
        "        user_message = \" \".join(user_prompt)\n",
        "\n",
        "        response_text = generate_response(\n",
        "            myModel,\n",
        "            _messages=[\n",
        "                {'role': 'system', \"content\": system_message},\n",
        "                {'role': 'user', \"content\": user_message}\n",
        "            ]\n",
        "        )\n",
        "    # 解析 JSON 数据\n",
        "        try:\n",
        "            response_text = response_text.strip(\"```json\").strip(\"```\").strip()\n",
        "            # 提取 JSON 对象\n",
        "            response_json = json.loads(response_text)\n",
        "\n",
        "            # 验证 JSON 格式是否包含所需字段\n",
        "            if not all(key in response_json for key in [\"summary\", \"is_buggy\", \"metric\"]):\n",
        "                raise ValueError(\"返回的 JSON 缺少必要字段\")\n",
        "\n",
        "            # 更新 Node 的字段\n",
        "            node.analysis = response_json[\"summary\"]\n",
        "            node.is_buggy = response_json[\"is_buggy\"]\n",
        "            node.metric = response_json[\"metric\"]\n",
        "            # 将 JSON 数据保存到文件\n",
        "            with open(\"execution_result.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
        "                json.dump(response_json, json_file, ensure_ascii=False, indent=4)\n",
        "\n",
        "        except json.JSONDecodeError:\n",
        "            # 如果解析失败，记录错误并标记为有问题的节点\n",
        "            print(f\"JSON 解析失败: {response_text}\")\n",
        "            node.analysis = \"LLM 返回的结果无法解析为 JSON\"\n",
        "            node.is_buggy = True\n",
        "            node.metric = 3.0\n",
        "        except ValueError as e:\n",
        "            # 如果 JSON 格式不符合要求，记录错误并标记为有问题的节点\n",
        "            print(f\"JSON 格式错误: {e}\")\n",
        "            node.analysis = \"LLM 返回的 JSON 不符合预期格式\"\n",
        "            node.is_buggy = True\n",
        "            node.metric = 3.0\n",
        "        except Exception as e:\n",
        "            # 捕获其他异常\n",
        "            print(f\"未知错误: {e}\")\n",
        "            node.analysis = \"评估过程中发生未知错误\"\n",
        "            node.is_buggy = True\n",
        "            node.metric = 3.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "di-9OGwOiZgl"
      },
      "source": [
        "### Text Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1csIXAO6i8i"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "\n",
        "def wrap_code(code: str, lang=\"python\") -> str:\n",
        "    \"\"\"Wraps code with three backticks.\"\"\"\n",
        "    return f\"```{lang}\\n{code}\\n```\"\n",
        "\n",
        "\n",
        "def is_valid_python_script(script):\n",
        "    \"\"\"Check if a script is a valid Python script.\"\"\"\n",
        "    try:\n",
        "        compile(script, \"<string>\", \"exec\")\n",
        "        return True\n",
        "    except SyntaxError:\n",
        "        return False\n",
        "\n",
        "\n",
        "def extract_jsons(text):\n",
        "    \"\"\"Extract all JSON objects from the text. Caveat: This function cannot handle nested JSON objects.\"\"\"\n",
        "    json_objects = []\n",
        "\n",
        "    # Find {} by regular expression\n",
        "    matches = re.findall(r\"\\{.*?\\}\", text, re.DOTALL)\n",
        "\n",
        "    # Try to transform string into json objects\n",
        "    for match in matches:\n",
        "        try:\n",
        "            json_obj = json.loads(match)\n",
        "            json_objects.append(json_obj)\n",
        "        except json.JSONDecodeError:\n",
        "            pass\n",
        "\n",
        "    return json_objects\n",
        "\n",
        "def trim_long_string(string, threshold=5100, k=2500):\n",
        "    # Check if the length of the string is longer than the threshold\n",
        "    if len(string) > threshold:\n",
        "        # Output the first k and last k characters\n",
        "        first_k_chars = string[:k]\n",
        "        last_k_chars = string[-k:]\n",
        "\n",
        "        truncated_len = len(string) - 2 * k\n",
        "\n",
        "        return f\"{first_k_chars}\\n ... [{truncated_len} characters truncated] ... \\n{last_k_chars}\"\n",
        "    else:\n",
        "        return string\n",
        "\n",
        "def extract_code(text):\n",
        "    \"\"\"Extract python code blocks from the text.\"\"\"\n",
        "    parsed_codes = []\n",
        "\n",
        "    # When code is in a text or python block\n",
        "    matches = re.findall(r\"```(python)?\\n*(.*?)\\n*```\", text, re.DOTALL)\n",
        "    for match in matches:\n",
        "        code_block = match[1]\n",
        "        parsed_codes.append(code_block)\n",
        "\n",
        "    # When the entire text is code or backticks of the code block is missing\n",
        "    if len(parsed_codes) == 0:\n",
        "        matches = re.findall(r\"^(```(python)?)?\\n?(.*?)\\n?(```)?$\", text, re.DOTALL)\n",
        "        if matches:\n",
        "            code_block = matches[0][2]\n",
        "            parsed_codes.append(code_block)\n",
        "\n",
        "    # validate the parsed codes\n",
        "    valid_code_blocks = [\n",
        "        c for c in parsed_codes if is_valid_python_script(c)\n",
        "    ]\n",
        "    return \"\\n\\n\".join(valid_code_blocks)\n",
        "\n",
        "def extract_text_up_to_code(s):\n",
        "    \"\"\"Extract (presumed) natural language text up to the start of the first code block.\"\"\"\n",
        "    if \"```\" not in s:\n",
        "        return \"\"\n",
        "    return s[: s.find(\"```\")].strip()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26WSVJyCnC1j"
      },
      "source": [
        "### Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-zUUVAXyBV7",
        "outputId": "0d2a65b8-7f37-4c41-9052-1b95ad5e5076"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in ./anaconda3/envs/mlworks/lib/python3.11/site-packages (2.2.3)\n",
            "Requirement already satisfied: numpy>=1.23.2 in ./anaconda3/envs/mlworks/lib/python3.11/site-packages (from pandas) (2.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./anaconda3/envs/mlworks/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./anaconda3/envs/mlworks/lib/python3.11/site-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./anaconda3/envs/mlworks/lib/python3.11/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in ./anaconda3/envs/mlworks/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8hRG2o7yeoc"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import humanize\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def preview_csv(p: Path) -> str:\n",
        "    \"\"\"Generate a textual preview of a csv file\"\"\"\n",
        "\n",
        "    df = pd.read_csv(p)\n",
        "\n",
        "    out = []\n",
        "\n",
        "    out.append(f\"-> {str(p)} has {df.shape[0]} rows and {df.shape[1]} columns.\")\n",
        "\n",
        "    # ================  TODO: Tell LLM agents which feature is useful for prediction ================\n",
        "\n",
        "    cols = df.columns.tolist()\n",
        "    cols_str = \", \".join(cols)\n",
        "    res = f\"The columns are: {cols_str}\"\n",
        "\n",
        "    out.append(res)\n",
        "\n",
        "    return \"\\n\".join(out)\n",
        "\n",
        "def data_preview_generate(base_path):\n",
        "    \"\"\"\n",
        "    Generate a textual preview of a directory\n",
        "    \"\"\"\n",
        "\n",
        "    result = []\n",
        "    files = [p for p in Path(base_path).iterdir()]\n",
        "\n",
        "    if not files:\n",
        "        return \"No CSV files found in the specified directory.\"\n",
        "\n",
        "    for f in sorted(files):\n",
        "        try:\n",
        "            result.append(preview_csv(f))\n",
        "        except Exception as e:\n",
        "            result.append(f\"Error processing {f}: {str(e)}\")\n",
        "\n",
        "    result = \"\\n\\n\".join(result)\n",
        "\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qeTrqDrbVtZ"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yeyuK6n6tY5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# DO NOT MODIFY THIS CELL\n",
        "class Config:\n",
        "    \"\"\"\n",
        "    A recursive configuration class that converts a dictionary into an object\n",
        "    with attributes accessible using dot notation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dictionary):\n",
        "        for key, value in dictionary.items():\n",
        "            if isinstance(value, dict):\n",
        "                value = Config(value)\n",
        "            setattr(self, key, value)\n",
        "\n",
        "def set_seed(seed=531):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "set_seed()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rGMZ96i6LwT"
      },
      "outputs": [],
      "source": [
        "# ================  TODO: config ================\n",
        "config = {\n",
        "    # experiment configurations\n",
        "    \"exp_name\": \"ML2025_HW2\",\n",
        "    \"data_dir\":  Path(\"/content/ML2025Spring-hw2-public\").resolve(),\n",
        "\n",
        "    # the description of the task\n",
        "   \"task_goal\":\n",
        "    \"\"\"\n",
        "  你的任务是基于前两天的调查结果和行为数据，预测美国各州在第3天检测出COVID-19阳性的概率。\n",
        "  这是一个回归的机器学习任务，请不要使用分类相关的机器学习算法。\n",
        "  给定的数据集中包含多个特征，但并非所有特征都与预测目标相关或适合建模。你需要对数据集进行分析，识别并选择对 testing_positive_day3 最有影响的特征。\n",
        "\n",
        "  在完成任务时，请注意以下要求：\n",
        "  1. 特征选择时，保留所有与地理区域相关的特征（如各州的编码特征，例如 AL、CA 等）。\n",
        "  2. 尝试多种回归模型（例如SVR、随机森林回归、梯度提升回归等），并通过超参数调优选择性能最佳的模型。\n",
        "  3. 使用交叉验证和网格搜索进行超参数调优，输出每个模型的最佳参数和对应的验证集 Mean Squared Error (MSE)。\n",
        "  4. 数据集是完整的，请不要在结果中输出数据集内容。\n",
        "  5. 最终，请对 Test 集进行预测，并保存预测结果。\n",
        "    \"\"\",\n",
        "\n",
        "    \"agent\": {\n",
        "        # the number of iterations\n",
        "        \"steps\": 20,\n",
        "        \"search\": {\n",
        "            # decide whether to debug or improve\n",
        "            \"debug_prob\": 0.5,\n",
        "            # the number of draft generated before improving/debugging\n",
        "            \"num_drafts\": 3,\n",
        "        },\n",
        "    },\n",
        "}\n",
        "\n",
        "cfg = Config(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_DTmIU8_Pkz"
      },
      "source": [
        "## Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05rMOHqy_lE7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "editable": true,
        "id": "YHG21H719_A3",
        "outputId": "62de6847-33d5-4916-b34b-63ea8607c4ee",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1/20 in progress...\n",
            "传入parse_exer_result的执行结果是: Best parameters for SVR: {'C': 1, 'epsilon': 0.2, 'kernel': 'linear'}\n",
            "Best MSE for SVR: 0.9960581929309686\n",
            "Best parameters for RandomForest: {'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 200}\n",
            "Best MSE for RandomForest: 1.072458657290075\n",
            "Best parameters for GradientBoosting: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
            "Best MSE for GradientBoosting: 1.0700934080592348\n",
            "Cross-validated MSE for SVR: 0.9960581929309686\n",
            "Cross-validated MSE for RandomForest: 1.0716296798377551\n",
            "Cross-validated MSE for GradientBoosting: 1.0706121784804945\n",
            "Execution time: 9 minutes seconds (time limit is 20 minutes).\n",
            "Step 1 completed.\n",
            "Latest Node ID: 77118aed0b2b4ed6be256a3291ad7c77\n",
            "Metric: 0.996\n",
            "Is Buggy: False\n",
            "Execution Time: 575.42 seconds\n",
            "Parent Node: None\n",
            "--------------------------------------------------\n",
            "Step 2/20 in progress...\n",
            "传入parse_exer_result的执行结果是: Selected Features: Index(['AL', 'AZ', 'CA', 'CO', 'CT', 'FL', 'GA', 'IL', 'IN', 'IA',\n",
            "       ...\n",
            "       'wothers_distanced_public_day2', 'wshop_indoors_day2',\n",
            "       'wrestaurant_indoors_day2', 'wworried_catch_covid_day2',\n",
            "       'hh_cmnty_cli_day2', 'nohh_cmnty_cli_day2', 'wearing_mask_7d_day2',\n",
            "       'public_transit_day2', 'worried_finances_day2', 'tested_positive_day2'],\n",
            "      dtype='object', length=123)\n",
            "Best parameters for RandomForest: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 300}\n",
            "Best MSE for RandomForest: 1.020193372224928\n",
            "Best parameters for GradientBoosting: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
            "Best MSE for GradientBoosting: 0.9639022660445058\n",
            "Best parameters for SVR: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
            "Best MSE for SVR: 0.9090846169246184\n",
            "Best model: SVR\n",
            "Execution time: 14 minutes seconds (time limit is 20 minutes).\n",
            "Step 2 completed.\n",
            "Latest Node ID: 4a9dcf6949ac4019a1bb6a9873ae2f96\n",
            "Metric: 0.909\n",
            "Is Buggy: False\n",
            "Execution Time: 894.50 seconds\n",
            "Parent Node: None\n",
            "--------------------------------------------------\n",
            "Step 3/20 in progress...\n",
            "传入parse_exer_result的执行结果是: joblib.externals.loky.process_executor._RemoteTraceback: \n",
            "\"\"\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n",
            "    r = call_item()\n",
            "        ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n",
            "    return self.fn(*self.args, **self.kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 598, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 598, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 139, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 854, in _fit_and_score\n",
            "    estimator = estimator.set_params(**clone(parameters, safe=False))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 320, in set_params\n",
            "    self._set_params(\"steps\", **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/metaestimators.py\", line 69, in _set_params\n",
            "    super().set_params(**params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 283, in set_params\n",
            "    raise ValueError(\n",
            "ValueError: Invalid parameter 'max_depth' for estimator Pipeline(steps=[('preprocessor',\n",
            "                 ColumnTransformer(transformers=[('num',\n",
            "                                                  Pipeline(steps=[('imputer',\n",
            "                                                                   SimpleImputer()),\n",
            "                                                                  ('scaler',\n",
            "                                                                   StandardScaler())]),\n",
            "                                                  ['cli_day1', 'ili_day1',\n",
            "                                                   'wnohh_cmnty_cli_day1',\n",
            "                                                   'wbelief_masking_effective_day1',\n",
            "                                                   'wbelief_distancing_effective_day1',\n",
            "                                                   'wcovid_vaccinated_friends_day1',\n",
            "          \n",
            " ... [3315 characters truncated] ... \n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 763, in _return_or_raise\n",
            "    raise self._result\n",
            "ValueError: Invalid parameter 'max_depth' for estimator Pipeline(steps=[('preprocessor',\n",
            "                 ColumnTransformer(transformers=[('num',\n",
            "                                                  Pipeline(steps=[('imputer',\n",
            "                                                                   SimpleImputer()),\n",
            "                                                                  ('scaler',\n",
            "                                                                   StandardScaler())]),\n",
            "                                                  ['cli_day1', 'ili_day1',\n",
            "                                                   'wnohh_cmnty_cli_day1',\n",
            "                                                   'wbelief_masking_effective_day1',\n",
            "                                                   'wbelief_distancing_effective_day1',\n",
            "                                                   'wcovid_vaccinated_friends_day1',\n",
            "                                                   'wlarge_event_indoors_day1',\n",
            "                                                   'wothers_masked_public_day1',...\n",
            "                                                   'wworried_catch_covid_day2', ...]),\n",
            "                                                 ('cat',\n",
            "                                                  Pipeline(steps=[('imputer',\n",
            "                                                                   SimpleImputer(fill_value='missing',\n",
            "                                                                                 strategy='constant')),\n",
            "                                                                  ('onehot',\n",
            "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
            "                                                  ['AL', 'AZ', 'CA', 'CO', 'CT',\n",
            "                                                   'FL', 'GA', 'IL', 'IN', 'IA',\n",
            "                                                   'KS', 'KY', 'LA', 'ME', 'MD',\n",
            "                                                   'MA', 'MI', 'MN', 'MO', 'NJ',\n",
            "                                                   'NM', 'NY', 'NC', 'OH', 'OK',\n",
            "                                                   'OR', 'PA', 'SC', 'TN', 'TX', ...])])),\n",
            "                ('model', RandomForestRegressor())]). Valid parameters are: ['memory', 'steps', 'transform_input', 'verbose'].\n",
            "Execution time: 2 seconds seconds (time limit is 20 minutes).\n",
            "Step 3 completed.\n",
            "Latest Node ID: d15f706fb29a429dbce9a2d8f7288421\n",
            "Metric: 3.0\n",
            "Is Buggy: True\n",
            "Execution Time: 2.91 seconds\n",
            "Parent Node: None\n",
            "--------------------------------------------------\n",
            "Step 4/20 in progress...\n",
            "传入parse_exer_result的执行结果是: joblib.externals.loky.process_executor._RemoteTraceback: \n",
            "\"\"\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n",
            "    r = call_item()\n",
            "        ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n",
            "    return self.fn(*self.args, **self.kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 598, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 598, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 139, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 854, in _fit_and_score\n",
            "    estimator = estimator.set_params(**clone(parameters, safe=False))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 320, in set_params\n",
            "    self._set_params(\"steps\", **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/metaestimators.py\", line 69, in _set_params\n",
            "    super().set_params(**params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 283, in set_params\n",
            "    raise ValueError(\n",
            "ValueError: Invalid parameter 'n_estimators' for estimator Pipeline(steps=[('preprocessor',\n",
            "                 ColumnTransformer(transformers=[('num',\n",
            "                                                  Pipeline(steps=[('imputer',\n",
            "                                                                   SimpleImputer()),\n",
            "                                                                  ('scaler',\n",
            "                                                                   StandardScaler())]),\n",
            "                                                  Index(['AL', 'AZ', 'CA', 'CO', 'CT', 'FL', 'GA', 'IL', 'IN', 'IA',\n",
            "       ...\n",
            "       'wothers_distanced_public_day2', 'wshop_indoors_day2',\n",
            "       'wrestaurant_indoors_day2', 'wworried_catch_covid_day2',\n",
            "       'hh_cmnty_cli_day2', 'nohh_cmnty_cli_d...\n",
            "       'public_transit_day2', 'worried_finances_day2', 'tested_positive_day2'],\n",
            "      dtype='object', length=123\n",
            " ... [2001 characters truncated] ... \n",
            "output if self.return_generator else list(output)\n",
            "                                                ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1650, in _get_outputs\n",
            "    yield from self._retrieve()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1754, in _retrieve\n",
            "    self._raise_error_fast()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1789, in _raise_error_fast\n",
            "    error_job.get_result(self.timeout)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 745, in get_result\n",
            "    return self._return_or_raise()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 763, in _return_or_raise\n",
            "    raise self._result\n",
            "ValueError: Invalid parameter 'n_estimators' for estimator Pipeline(steps=[('preprocessor',\n",
            "                 ColumnTransformer(transformers=[('num',\n",
            "                                                  Pipeline(steps=[('imputer',\n",
            "                                                                   SimpleImputer()),\n",
            "                                                                  ('scaler',\n",
            "                                                                   StandardScaler())]),\n",
            "                                                  Index(['AL', 'AZ', 'CA', 'CO', 'CT', 'FL', 'GA', 'IL', 'IN', 'IA',\n",
            "       ...\n",
            "       'wothers_distanced_public_day2', 'wshop_indoors_day2',\n",
            "       'wrestaurant_indoors_day2', 'wworried_catch_covid_day2',\n",
            "       'hh_cmnty_cli_day2', 'nohh_cmnty_cli_d...\n",
            "       'public_transit_day2', 'worried_finances_day2', 'tested_positive_day2'],\n",
            "      dtype='object', length=123)),\n",
            "                                                 ('cat',\n",
            "                                                  Pipeline(steps=[('imputer',\n",
            "                                                                   SimpleImputer(strategy='most_frequent')),\n",
            "                                                                  ('onehot',\n",
            "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
            "                                                  Index([], dtype='object'))])),\n",
            "                ('feature_selection',\n",
            "                 SelectFromModel(estimator=LinearRegression())),\n",
            "                ('model', RandomForestRegressor(random_state=42))]). Valid parameters are: ['memory', 'steps', 'transform_input', 'verbose'].\n",
            "Execution time: 2 seconds seconds (time limit is 20 minutes).\n",
            "Step 4 completed.\n",
            "Latest Node ID: 86eb913ae4db4f2d94c3269afad36857\n",
            "Metric: 3.0\n",
            "Is Buggy: True\n",
            "Execution Time: 2.87 seconds\n",
            "Parent Node ID: 4a9dcf6949ac4019a1bb6a9873ae2f96\n",
            "Parent Metric: 0.909\n",
            "Parent Is Buggy: False\n",
            "--------------------------------------------------\n",
            "Step 5/20 in progress...\n",
            "传入parse_exer_result的执行结果是: Selected Features: Index(['AL', 'AZ', 'CA', 'CO', 'CT', 'FL', 'GA', 'IL', 'IN', 'IA',\n",
            "       ...\n",
            "       'wothers_distanced_public_day2', 'wshop_indoors_day2',\n",
            "       'wrestaurant_indoors_day2', 'wworried_catch_covid_day2',\n",
            "       'hh_cmnty_cli_day2', 'nohh_cmnty_cli_day2', 'wearing_mask_7d_day2',\n",
            "       'public_transit_day2', 'worried_finances_day2', 'tested_positive_day2'],\n",
            "      dtype='object', length=123)\n",
            "Best parameters for RandomForest: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 300}\n",
            "Best MSE for RandomForest: 1.020193372224928\n",
            "Best parameters for GradientBoosting: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
            "Best MSE for GradientBoosting: 0.9639022660445058\n",
            "Best parameters for SVR: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
            "Best MSE for SVR: 0.9090846169246184\n",
            "Best model: SVR\n",
            "Execution time: 14 minutes seconds (time limit is 20 minutes).\n",
            "Step 5 completed.\n",
            "Latest Node ID: e5c6908a12634321b2b123501f696229\n",
            "Metric: 0.909\n",
            "Is Buggy: False\n",
            "Execution Time: 893.69 seconds\n",
            "Parent Node ID: 4a9dcf6949ac4019a1bb6a9873ae2f96\n",
            "Parent Metric: 0.909\n",
            "Parent Is Buggy: False\n",
            "--------------------------------------------------\n",
            "Step 6/20 in progress...\n",
            "传入parse_exer_result的执行结果是: Selected Features: Index(['AL', 'AZ', 'CA', 'CO', 'CT', 'FL', 'GA', 'IL', 'IN', 'IA',\n",
            "       ...\n",
            "       'wothers_distanced_public_day2', 'wshop_indoors_day2',\n",
            "       'wrestaurant_indoors_day2', 'wworried_catch_covid_day2',\n",
            "       'hh_cmnty_cli_day2', 'nohh_cmnty_cli_day2', 'wearing_mask_7d_day2',\n",
            "       'public_transit_day2', 'worried_finances_day2', 'tested_positive_day2'],\n",
            "      dtype='object', length=123)\n",
            "Best parameters for RandomForest: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 300}\n",
            "Best MSE for RandomForest: 1.020193372224928\n",
            "Best parameters for GradientBoosting: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
            "Best MSE for GradientBoosting: 0.9639022660445058\n",
            "Best parameters for SVR: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
            "Best MSE for SVR: 0.9090846169246184\n",
            "Best model: SVR\n",
            "Execution time: 14 minutes seconds (time limit is 20 minutes).\n",
            "Step 6 completed.\n",
            "Latest Node ID: 46fb56dba2cb4037b5e127ded14fbb3b\n",
            "Metric: 0.909\n",
            "Is Buggy: False\n",
            "Execution Time: 893.95 seconds\n",
            "Parent Node ID: 4a9dcf6949ac4019a1bb6a9873ae2f96\n",
            "Parent Metric: 0.909\n",
            "Parent Is Buggy: False\n",
            "--------------------------------------------------\n",
            "Step 7/20 in progress...\n",
            "传入parse_exer_result的执行结果是: Traceback (most recent call last):\n",
            "  File \"<ipython-input-7-50e78fef4f4a>\", line 144, in _run_session\n",
            "    exec(compile(code, self.agent_file_name, \"exec\"), global_scope)\n",
            "  File \"runfile.py\", line 87, in <module>\n",
            "    grid_search.fit(X, y)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\", line 1024, in fit\n",
            "    self._run_search(evaluate_candidates)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\", line 1951, in _run_search\n",
            "    evaluate_candidates(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\", line 1001, in evaluate_candidates\n",
            "    _warn_or_raise_about_fit_failures(out, self.error_score)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 517, in _warn_or_raise_about_fit_failures\n",
            "    raise ValueError(all_fits_failed_message)\n",
            "ValueError: \n",
            "All the 50 fits failed.\n",
            "It is very likely that your model is misconfigured.\n",
            "You can try to debug the error by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "50 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 654, in fit\n",
            "    Xt = self._fit(X, y, routed_params, raw_params=params)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 588, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/memory.py\", line 312, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **params.get\n",
            " ... [1166 characters truncated] ... \n",
            "MA', 'MI', 'MN', 'MO', 'NJ', 'NM', 'NY', 'NC', 'OH', 'OK', 'OR', 'PA', 'SC', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI', 'cli_day1', 'ili_day1', 'wnohh_cmnty_cli_day1', 'wbelief_masking_effective_day1', 'wbelief_distancing_effective_day1', 'wcovid_vaccinated_friends_day1', 'wlarge_event_indoors_day1', 'wothers_masked_public_day1', 'wothers_distanced_public_day1', 'wshop_indoors_day1', 'wrestaurant_indoors_day1', 'wworried_catch_covid_day1', 'hh_cmnty_cli_day1', 'nohh_cmnty_cli_day1', 'wearing_mask_7d_day1', 'public_transit_day1', 'worried_finances_day1', 'tested_positive_day1', 'cli_day2', 'ili_day2', 'wnohh_cmnty_cli_day2', 'wbelief_masking_effective_day2', 'wbelief_distancing_effective_day2', 'wcovid_vaccinated_friends_day2', 'wlarge_event_indoors_day2', 'wothers_masked_public_day2', 'wothers_distanced_public_day2', 'wshop_indoors_day2', 'wrestaurant_indoors_day2', 'wworried_catch_covid_day2', 'hh_cmnty_cli_day2', 'nohh_cmnty_cli_day2', 'wearing_mask_7d_day2', 'public_transit_day2', 'worried_finances_day2', 'tested_positive_day2', 'cli_day3', 'ili_day3', 'wnohh_cmnty_cli_day3', 'wbelief_masking_effective_day3', 'wbelief_distancing_effective_day3', 'wcovid_vaccinated_friends_day3', 'wlarge_event_indoors_day3', 'wothers_masked_public_day3', 'wothers_distanced_public_day3', 'wshop_indoors_day3', 'wrestaurant_indoors_day3', 'wworried_catch_covid_day3', 'hh_cmnty_cli_day3', 'nohh_cmnty_cli_day3', 'wearing_mask_7d_day3', 'public_transit_day3', 'worried_finances_day3', 'cli_day1', 'ili_day1', 'wnohh_cmnty_cli_day1', 'wbelief_masking_effective_day1', 'wbelief_distancing_effective_day1', 'wcovid_vaccinated_friends_day1', 'wlarge_event_indoors_day1', 'wothers_masked_public_day1', 'wothers_distanced_public_day1', 'wshop_indoors_day1', 'wrestaurant_indoors_day1', 'wworried_catch_covid_day1', 'hh_cmnty_cli_day1', 'nohh_cmnty_cli_day1', 'wearing_mask_7d_day1', 'public_transit_day1', 'worried_finances_day1', 'tested_positive_day1', 'cli_day2', 'ili_day2', 'wnohh_cmnty_cli_day2', 'wbelief_masking_effective_day2', 'wbelief_distancing_effective_day2', 'wcovid_vaccinated_friends_day2', 'wlarge_event_indoors_day2', 'wothers_masked_public_day2', 'wothers_distanced_public_day2', 'wshop_indoors_day2', 'wrestaurant_indoors_day2', 'wworried_catch_covid_day2', 'hh_cmnty_cli_day2', 'nohh_cmnty_cli_day2', 'wearing_mask_7d_day2', 'public_transit_day2', 'worried_finances_day2', 'tested_positive_day2'], are not unique in dataframe\n",
            "\n",
            "Execution time: 2 seconds seconds (time limit is 20 minutes).\n",
            "Step 7 completed.\n",
            "Latest Node ID: 427ccb9069b944e5960b31a0d8165555\n",
            "Metric: 3.0\n",
            "Is Buggy: True\n",
            "Execution Time: 2.96 seconds\n",
            "Parent Node ID: 86eb913ae4db4f2d94c3269afad36857\n",
            "Parent Metric: 3.0\n",
            "Parent Is Buggy: True\n",
            "--------------------------------------------------\n",
            "Step 8/20 in progress...\n",
            "传入parse_exer_result的执行结果是: Traceback (most recent call last):\n",
            "  File \"<ipython-input-7-50e78fef4f4a>\", line 144, in _run_session\n",
            "    exec(compile(code, self.agent_file_name, \"exec\"), global_scope)\n",
            "  File \"runfile.py\", line 87, in <module>\n",
            "    grid_search.fit(X[selected_features], y)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\", line 1024, in fit\n",
            "    self._run_search(evaluate_candidates)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\", line 1571, in _run_search\n",
            "    evaluate_candidates(ParameterGrid(self.param_grid))\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\", line 1001, in evaluate_candidates\n",
            "    _warn_or_raise_about_fit_failures(out, self.error_score)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 517, in _warn_or_raise_about_fit_failures\n",
            "    raise ValueError(all_fits_failed_message)\n",
            "ValueError: \n",
            "All the 90 fits failed.\n",
            "It is very likely that your model is misconfigured.\n",
            "You can try to debug the error by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "90 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 654, in fit\n",
            "    Xt = self._fit(X, y, routed_params, raw_params=params)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 588, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/memory.py\", line 312, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n",
            "    \n",
            " ... [1572 characters truncated] ... \n",
            "3.11/dist-packages/sklearn/utils/parallel.py\", line 139, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 718, in fit_transform\n",
            "    Xt = self._fit(X, y, routed_params)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 588, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/memory.py\", line 312, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 921, in fit_transform\n",
            "    return self.fit(X, y, **fit_params).transform(X)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 434, in fit\n",
            "    X = self._validate_input(X, in_fit=True)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 412, in _validate_input\n",
            "    raise ValueError(err_msg)\n",
            "ValueError: fill_value='missing' (of type <class 'str'>) cannot be cast to the input data that is dtype('int64'). Make sure that both dtypes are of the same kind.\n",
            "\n",
            "Execution time: 3 seconds seconds (time limit is 20 minutes).\n",
            "Step 8 completed.\n",
            "Latest Node ID: cfb9c0be68f74fffa2a605ba0f3ca06b\n",
            "Metric: 3.0\n",
            "Is Buggy: True\n",
            "Execution Time: 3.16 seconds\n",
            "Parent Node ID: d15f706fb29a429dbce9a2d8f7288421\n",
            "Parent Metric: 3.0\n",
            "Parent Is Buggy: True\n",
            "--------------------------------------------------\n",
            "Step 9/20 in progress...\n",
            "传入parse_exer_result的执行结果是: Traceback (most recent call last):\n",
            "  File \"<ipython-input-7-50e78fef4f4a>\", line 144, in _run_session\n",
            "    exec(compile(code, self.agent_file_name, \"exec\"), global_scope)\n",
            "  File \"runfile.py\", line 87, in <module>\n",
            "    grid_search.fit(X, y)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\", line 1024, in fit\n",
            "    self._run_search(evaluate_candidates)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\", line 1951, in _run_search\n",
            "    evaluate_candidates(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\", line 1001, in evaluate_candidates\n",
            "    _warn_or_raise_about_fit_failures(out, self.error_score)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 517, in _warn_or_raise_about_fit_failures\n",
            "    raise ValueError(all_fits_failed_message)\n",
            "ValueError: \n",
            "All the 50 fits failed.\n",
            "It is very likely that your model is misconfigured.\n",
            "You can try to debug the error by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "50 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 654, in fit\n",
            "    Xt = self._fit(X, y, routed_params, raw_params=params)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 588, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/memory.py\", line 312, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **params.get\n",
            " ... [1166 characters truncated] ... \n",
            "MA', 'MI', 'MN', 'MO', 'NJ', 'NM', 'NY', 'NC', 'OH', 'OK', 'OR', 'PA', 'SC', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI', 'cli_day1', 'ili_day1', 'wnohh_cmnty_cli_day1', 'wbelief_masking_effective_day1', 'wbelief_distancing_effective_day1', 'wcovid_vaccinated_friends_day1', 'wlarge_event_indoors_day1', 'wothers_masked_public_day1', 'wothers_distanced_public_day1', 'wshop_indoors_day1', 'wrestaurant_indoors_day1', 'wworried_catch_covid_day1', 'hh_cmnty_cli_day1', 'nohh_cmnty_cli_day1', 'wearing_mask_7d_day1', 'public_transit_day1', 'worried_finances_day1', 'tested_positive_day1', 'cli_day2', 'ili_day2', 'wnohh_cmnty_cli_day2', 'wbelief_masking_effective_day2', 'wbelief_distancing_effective_day2', 'wcovid_vaccinated_friends_day2', 'wlarge_event_indoors_day2', 'wothers_masked_public_day2', 'wothers_distanced_public_day2', 'wshop_indoors_day2', 'wrestaurant_indoors_day2', 'wworried_catch_covid_day2', 'hh_cmnty_cli_day2', 'nohh_cmnty_cli_day2', 'wearing_mask_7d_day2', 'public_transit_day2', 'worried_finances_day2', 'tested_positive_day2', 'cli_day3', 'ili_day3', 'wnohh_cmnty_cli_day3', 'wbelief_masking_effective_day3', 'wbelief_distancing_effective_day3', 'wcovid_vaccinated_friends_day3', 'wlarge_event_indoors_day3', 'wothers_masked_public_day3', 'wothers_distanced_public_day3', 'wshop_indoors_day3', 'wrestaurant_indoors_day3', 'wworried_catch_covid_day3', 'hh_cmnty_cli_day3', 'nohh_cmnty_cli_day3', 'wearing_mask_7d_day3', 'public_transit_day3', 'worried_finances_day3', 'cli_day1', 'ili_day1', 'wnohh_cmnty_cli_day1', 'wbelief_masking_effective_day1', 'wbelief_distancing_effective_day1', 'wcovid_vaccinated_friends_day1', 'wlarge_event_indoors_day1', 'wothers_masked_public_day1', 'wothers_distanced_public_day1', 'wshop_indoors_day1', 'wrestaurant_indoors_day1', 'wworried_catch_covid_day1', 'hh_cmnty_cli_day1', 'nohh_cmnty_cli_day1', 'wearing_mask_7d_day1', 'public_transit_day1', 'worried_finances_day1', 'tested_positive_day1', 'cli_day2', 'ili_day2', 'wnohh_cmnty_cli_day2', 'wbelief_masking_effective_day2', 'wbelief_distancing_effective_day2', 'wcovid_vaccinated_friends_day2', 'wlarge_event_indoors_day2', 'wothers_masked_public_day2', 'wothers_distanced_public_day2', 'wshop_indoors_day2', 'wrestaurant_indoors_day2', 'wworried_catch_covid_day2', 'hh_cmnty_cli_day2', 'nohh_cmnty_cli_day2', 'wearing_mask_7d_day2', 'public_transit_day2', 'worried_finances_day2', 'tested_positive_day2'], are not unique in dataframe\n",
            "\n",
            "Execution time: 3 seconds seconds (time limit is 20 minutes).\n",
            "Step 9 completed.\n",
            "Latest Node ID: 523872abaed94fb1aab0972b8b2e9b6f\n",
            "Metric: 3.0\n",
            "Is Buggy: True\n",
            "Execution Time: 3.06 seconds\n",
            "Parent Node ID: 427ccb9069b944e5960b31a0d8165555\n",
            "Parent Metric: 3.0\n",
            "Parent Is Buggy: True\n",
            "--------------------------------------------------\n",
            "Step 10/20 in progress...\n",
            "传入parse_exer_result的执行结果是: Best parameters for RandomForest: {'model__max_depth': 10, 'model__min_samples_split': 10, 'model__n_estimators': 200}\n",
            "Best MSE for RandomForest: 1.0119156410253773\n",
            "Best parameters for GradientBoosting: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__n_estimators': 100}\n",
            "Best MSE for GradientBoosting: 0.9893191068348512\n",
            "Best parameters for SVR: {'model__C': 100, 'model__epsilon': 0.3, 'model__kernel': 'rbf'}\n",
            "Best MSE for SVR: 0.895018895576837\n",
            "Execution time: 7 minutes seconds (time limit is 20 minutes).\n",
            "Step 10 completed.\n",
            "Latest Node ID: 176aad9d999646d7b2116ad070246504\n",
            "Metric: 0.895\n",
            "Is Buggy: False\n",
            "Execution Time: 429.47 seconds\n",
            "Parent Node ID: cfb9c0be68f74fffa2a605ba0f3ca06b\n",
            "Parent Metric: 3.0\n",
            "Parent Is Buggy: True\n",
            "--------------------------------------------------\n",
            "Step 11/20 in progress...\n",
            "传入parse_exer_result的执行结果是: Best parameters for RandomForest: {'model__max_depth': 10, 'model__min_samples_split': 10, 'model__n_estimators': 200}\n",
            "Best MSE for RandomForest: 1.012462130308692\n",
            "Best parameters for GradientBoosting: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__n_estimators': 100}\n",
            "Best MSE for GradientBoosting: 0.9884457175671182\n",
            "Best parameters for SVR: {'model__C': 100, 'model__epsilon': 0.3, 'model__kernel': 'rbf'}\n",
            "Best MSE for SVR: 0.895018895576837\n",
            "Execution time: 7 minutes seconds (time limit is 20 minutes).\n",
            "Step 11 completed.\n",
            "Latest Node ID: 355bfb142acf43feb59dba698c66ee19\n",
            "Metric: 0.895\n",
            "Is Buggy: False\n",
            "Execution Time: 425.27 seconds\n",
            "Parent Node ID: 176aad9d999646d7b2116ad070246504\n",
            "Parent Metric: 0.895\n",
            "Parent Is Buggy: False\n",
            "--------------------------------------------------\n",
            "Step 12/20 in progress...\n",
            "传入parse_exer_result的执行结果是: joblib.externals.loky.process_executor._RemoteTraceback: \n",
            "\"\"\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n",
            "    r = call_item()\n",
            "        ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n",
            "    return self.fn(*self.args, **self.kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 598, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 598, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 139, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 654, in fit\n",
            "    Xt = self._fit(X, y, routed_params, raw_params=params)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 588, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/memory.py\", line 312, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^\n",
            " ... [5326 characters truncated] ... \n",
            "'MA', 'MI', 'MN', 'MO', 'NJ', 'NM', 'NY', 'NC', 'OH', 'OK', 'OR', 'PA', 'SC', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI', 'cli_day1', 'ili_day1', 'wnohh_cmnty_cli_day1', 'wbelief_masking_effective_day1', 'wbelief_distancing_effective_day1', 'wcovid_vaccinated_friends_day1', 'wlarge_event_indoors_day1', 'wothers_masked_public_day1', 'wothers_distanced_public_day1', 'wshop_indoors_day1', 'wrestaurant_indoors_day1', 'wworried_catch_covid_day1', 'hh_cmnty_cli_day1', 'nohh_cmnty_cli_day1', 'wearing_mask_7d_day1', 'public_transit_day1', 'worried_finances_day1', 'tested_positive_day1', 'cli_day2', 'ili_day2', 'wnohh_cmnty_cli_day2', 'wbelief_masking_effective_day2', 'wbelief_distancing_effective_day2', 'wcovid_vaccinated_friends_day2', 'wlarge_event_indoors_day2', 'wothers_masked_public_day2', 'wothers_distanced_public_day2', 'wshop_indoors_day2', 'wrestaurant_indoors_day2', 'wworried_catch_covid_day2', 'hh_cmnty_cli_day2', 'nohh_cmnty_cli_day2', 'wearing_mask_7d_day2', 'public_transit_day2', 'worried_finances_day2', 'tested_positive_day2', 'cli_day3', 'ili_day3', 'wnohh_cmnty_cli_day3', 'wbelief_masking_effective_day3', 'wbelief_distancing_effective_day3', 'wcovid_vaccinated_friends_day3', 'wlarge_event_indoors_day3', 'wothers_masked_public_day3', 'wothers_distanced_public_day3', 'wshop_indoors_day3', 'wrestaurant_indoors_day3', 'wworried_catch_covid_day3', 'hh_cmnty_cli_day3', 'nohh_cmnty_cli_day3', 'wearing_mask_7d_day3', 'public_transit_day3', 'worried_finances_day3', 'cli_day1', 'ili_day1', 'wnohh_cmnty_cli_day1', 'wbelief_masking_effective_day1', 'wbelief_distancing_effective_day1', 'wcovid_vaccinated_friends_day1', 'wlarge_event_indoors_day1', 'wothers_masked_public_day1', 'wothers_distanced_public_day1', 'wshop_indoors_day1', 'wrestaurant_indoors_day1', 'wworried_catch_covid_day1', 'hh_cmnty_cli_day1', 'nohh_cmnty_cli_day1', 'wearing_mask_7d_day1', 'public_transit_day1', 'worried_finances_day1', 'tested_positive_day1', 'cli_day2', 'ili_day2', 'wnohh_cmnty_cli_day2', 'wbelief_masking_effective_day2', 'wbelief_distancing_effective_day2', 'wcovid_vaccinated_friends_day2', 'wlarge_event_indoors_day2', 'wothers_masked_public_day2', 'wothers_distanced_public_day2', 'wshop_indoors_day2', 'wrestaurant_indoors_day2', 'wworried_catch_covid_day2', 'hh_cmnty_cli_day2', 'nohh_cmnty_cli_day2', 'wearing_mask_7d_day2', 'public_transit_day2', 'worried_finances_day2', 'tested_positive_day2'], are not unique in dataframe\n",
            "Execution time: 2 seconds seconds (time limit is 20 minutes).\n",
            "Step 12 completed.\n",
            "Latest Node ID: 2c978f8a68d44d4f961f4d75fc6d0b4c\n",
            "Metric: 3.0\n",
            "Is Buggy: True\n",
            "Execution Time: 2.78 seconds\n",
            "Parent Node ID: 523872abaed94fb1aab0972b8b2e9b6f\n",
            "Parent Metric: 3.0\n",
            "Parent Is Buggy: True\n",
            "--------------------------------------------------\n",
            "Step 13/20 in progress...\n",
            "传入parse_exer_result的执行结果是: joblib.externals.loky.process_executor._RemoteTraceback: \n",
            "\"\"\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n",
            "    r = call_item()\n",
            "        ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n",
            "    return self.fn(*self.args, **self.kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 598, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 598, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 139, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 654, in fit\n",
            "    Xt = self._fit(X, y, routed_params, raw_params=params)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 588, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/memory.py\", line 312, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^\n",
            " ... [5326 characters truncated] ... \n",
            "'MA', 'MI', 'MN', 'MO', 'NJ', 'NM', 'NY', 'NC', 'OH', 'OK', 'OR', 'PA', 'SC', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI', 'cli_day1', 'ili_day1', 'wnohh_cmnty_cli_day1', 'wbelief_masking_effective_day1', 'wbelief_distancing_effective_day1', 'wcovid_vaccinated_friends_day1', 'wlarge_event_indoors_day1', 'wothers_masked_public_day1', 'wothers_distanced_public_day1', 'wshop_indoors_day1', 'wrestaurant_indoors_day1', 'wworried_catch_covid_day1', 'hh_cmnty_cli_day1', 'nohh_cmnty_cli_day1', 'wearing_mask_7d_day1', 'public_transit_day1', 'worried_finances_day1', 'tested_positive_day1', 'cli_day2', 'ili_day2', 'wnohh_cmnty_cli_day2', 'wbelief_masking_effective_day2', 'wbelief_distancing_effective_day2', 'wcovid_vaccinated_friends_day2', 'wlarge_event_indoors_day2', 'wothers_masked_public_day2', 'wothers_distanced_public_day2', 'wshop_indoors_day2', 'wrestaurant_indoors_day2', 'wworried_catch_covid_day2', 'hh_cmnty_cli_day2', 'nohh_cmnty_cli_day2', 'wearing_mask_7d_day2', 'public_transit_day2', 'worried_finances_day2', 'tested_positive_day2', 'cli_day3', 'ili_day3', 'wnohh_cmnty_cli_day3', 'wbelief_masking_effective_day3', 'wbelief_distancing_effective_day3', 'wcovid_vaccinated_friends_day3', 'wlarge_event_indoors_day3', 'wothers_masked_public_day3', 'wothers_distanced_public_day3', 'wshop_indoors_day3', 'wrestaurant_indoors_day3', 'wworried_catch_covid_day3', 'hh_cmnty_cli_day3', 'nohh_cmnty_cli_day3', 'wearing_mask_7d_day3', 'public_transit_day3', 'worried_finances_day3', 'cli_day1', 'ili_day1', 'wnohh_cmnty_cli_day1', 'wbelief_masking_effective_day1', 'wbelief_distancing_effective_day1', 'wcovid_vaccinated_friends_day1', 'wlarge_event_indoors_day1', 'wothers_masked_public_day1', 'wothers_distanced_public_day1', 'wshop_indoors_day1', 'wrestaurant_indoors_day1', 'wworried_catch_covid_day1', 'hh_cmnty_cli_day1', 'nohh_cmnty_cli_day1', 'wearing_mask_7d_day1', 'public_transit_day1', 'worried_finances_day1', 'tested_positive_day1', 'cli_day2', 'ili_day2', 'wnohh_cmnty_cli_day2', 'wbelief_masking_effective_day2', 'wbelief_distancing_effective_day2', 'wcovid_vaccinated_friends_day2', 'wlarge_event_indoors_day2', 'wothers_masked_public_day2', 'wothers_distanced_public_day2', 'wshop_indoors_day2', 'wrestaurant_indoors_day2', 'wworried_catch_covid_day2', 'hh_cmnty_cli_day2', 'nohh_cmnty_cli_day2', 'wearing_mask_7d_day2', 'public_transit_day2', 'worried_finances_day2', 'tested_positive_day2'], are not unique in dataframe\n",
            "Execution time: 2 seconds seconds (time limit is 20 minutes).\n",
            "Step 13 completed.\n",
            "Latest Node ID: 6980184392064c91a6089bdfdba22e77\n",
            "Metric: 3.0\n",
            "Is Buggy: True\n",
            "Execution Time: 2.83 seconds\n",
            "Parent Node ID: 2c978f8a68d44d4f961f4d75fc6d0b4c\n",
            "Parent Metric: 3.0\n",
            "Parent Is Buggy: True\n",
            "--------------------------------------------------\n",
            "Step 14/20 in progress...\n",
            "传入parse_exer_result的执行结果是: joblib.externals.loky.process_executor._RemoteTraceback: \n",
            "\"\"\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n",
            "    r = call_item()\n",
            "        ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n",
            "    return self.fn(*self.args, **self.kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 598, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 598, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 139, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 654, in fit\n",
            "    Xt = self._fit(X, y, routed_params, raw_params=params)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 588, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/memory.py\", line 312, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^\n",
            " ... [5326 characters truncated] ... \n",
            "'MA', 'MI', 'MN', 'MO', 'NJ', 'NM', 'NY', 'NC', 'OH', 'OK', 'OR', 'PA', 'SC', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI', 'cli_day1', 'ili_day1', 'wnohh_cmnty_cli_day1', 'wbelief_masking_effective_day1', 'wbelief_distancing_effective_day1', 'wcovid_vaccinated_friends_day1', 'wlarge_event_indoors_day1', 'wothers_masked_public_day1', 'wothers_distanced_public_day1', 'wshop_indoors_day1', 'wrestaurant_indoors_day1', 'wworried_catch_covid_day1', 'hh_cmnty_cli_day1', 'nohh_cmnty_cli_day1', 'wearing_mask_7d_day1', 'public_transit_day1', 'worried_finances_day1', 'tested_positive_day1', 'cli_day2', 'ili_day2', 'wnohh_cmnty_cli_day2', 'wbelief_masking_effective_day2', 'wbelief_distancing_effective_day2', 'wcovid_vaccinated_friends_day2', 'wlarge_event_indoors_day2', 'wothers_masked_public_day2', 'wothers_distanced_public_day2', 'wshop_indoors_day2', 'wrestaurant_indoors_day2', 'wworried_catch_covid_day2', 'hh_cmnty_cli_day2', 'nohh_cmnty_cli_day2', 'wearing_mask_7d_day2', 'public_transit_day2', 'worried_finances_day2', 'tested_positive_day2', 'cli_day3', 'ili_day3', 'wnohh_cmnty_cli_day3', 'wbelief_masking_effective_day3', 'wbelief_distancing_effective_day3', 'wcovid_vaccinated_friends_day3', 'wlarge_event_indoors_day3', 'wothers_masked_public_day3', 'wothers_distanced_public_day3', 'wshop_indoors_day3', 'wrestaurant_indoors_day3', 'wworried_catch_covid_day3', 'hh_cmnty_cli_day3', 'nohh_cmnty_cli_day3', 'wearing_mask_7d_day3', 'public_transit_day3', 'worried_finances_day3', 'cli_day1', 'ili_day1', 'wnohh_cmnty_cli_day1', 'wbelief_masking_effective_day1', 'wbelief_distancing_effective_day1', 'wcovid_vaccinated_friends_day1', 'wlarge_event_indoors_day1', 'wothers_masked_public_day1', 'wothers_distanced_public_day1', 'wshop_indoors_day1', 'wrestaurant_indoors_day1', 'wworried_catch_covid_day1', 'hh_cmnty_cli_day1', 'nohh_cmnty_cli_day1', 'wearing_mask_7d_day1', 'public_transit_day1', 'worried_finances_day1', 'tested_positive_day1', 'cli_day2', 'ili_day2', 'wnohh_cmnty_cli_day2', 'wbelief_masking_effective_day2', 'wbelief_distancing_effective_day2', 'wcovid_vaccinated_friends_day2', 'wlarge_event_indoors_day2', 'wothers_masked_public_day2', 'wothers_distanced_public_day2', 'wshop_indoors_day2', 'wrestaurant_indoors_day2', 'wworried_catch_covid_day2', 'hh_cmnty_cli_day2', 'nohh_cmnty_cli_day2', 'wearing_mask_7d_day2', 'public_transit_day2', 'worried_finances_day2', 'tested_positive_day2'], are not unique in dataframe\n",
            "Execution time: 2 seconds seconds (time limit is 20 minutes).\n",
            "Step 14 completed.\n",
            "Latest Node ID: 17a867fc254a41759ffe5c9f932a2c46\n",
            "Metric: 3.0\n",
            "Is Buggy: True\n",
            "Execution Time: 2.85 seconds\n",
            "Parent Node ID: 6980184392064c91a6089bdfdba22e77\n",
            "Parent Metric: 3.0\n",
            "Parent Is Buggy: True\n",
            "--------------------------------------------------\n",
            "Step 15/20 in progress...\n",
            "传入parse_exer_result的执行结果是: joblib.externals.loky.process_executor._RemoteTraceback: \n",
            "\"\"\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n",
            "    r = call_item()\n",
            "        ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n",
            "    return self.fn(*self.args, **self.kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 598, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 598, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 139, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 654, in fit\n",
            "    Xt = self._fit(X, y, routed_params, raw_params=params)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 588, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/memory.py\", line 312, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^\n",
            " ... [5326 characters truncated] ... \n",
            "'MA', 'MI', 'MN', 'MO', 'NJ', 'NM', 'NY', 'NC', 'OH', 'OK', 'OR', 'PA', 'SC', 'TN', 'TX', 'VA', 'WA', 'WV', 'WI', 'cli_day1', 'ili_day1', 'wnohh_cmnty_cli_day1', 'wbelief_masking_effective_day1', 'wbelief_distancing_effective_day1', 'wcovid_vaccinated_friends_day1', 'wlarge_event_indoors_day1', 'wothers_masked_public_day1', 'wothers_distanced_public_day1', 'wshop_indoors_day1', 'wrestaurant_indoors_day1', 'wworried_catch_covid_day1', 'hh_cmnty_cli_day1', 'nohh_cmnty_cli_day1', 'wearing_mask_7d_day1', 'public_transit_day1', 'worried_finances_day1', 'tested_positive_day1', 'cli_day2', 'ili_day2', 'wnohh_cmnty_cli_day2', 'wbelief_masking_effective_day2', 'wbelief_distancing_effective_day2', 'wcovid_vaccinated_friends_day2', 'wlarge_event_indoors_day2', 'wothers_masked_public_day2', 'wothers_distanced_public_day2', 'wshop_indoors_day2', 'wrestaurant_indoors_day2', 'wworried_catch_covid_day2', 'hh_cmnty_cli_day2', 'nohh_cmnty_cli_day2', 'wearing_mask_7d_day2', 'public_transit_day2', 'worried_finances_day2', 'tested_positive_day2', 'cli_day3', 'ili_day3', 'wnohh_cmnty_cli_day3', 'wbelief_masking_effective_day3', 'wbelief_distancing_effective_day3', 'wcovid_vaccinated_friends_day3', 'wlarge_event_indoors_day3', 'wothers_masked_public_day3', 'wothers_distanced_public_day3', 'wshop_indoors_day3', 'wrestaurant_indoors_day3', 'wworried_catch_covid_day3', 'hh_cmnty_cli_day3', 'nohh_cmnty_cli_day3', 'wearing_mask_7d_day3', 'public_transit_day3', 'worried_finances_day3', 'cli_day1', 'ili_day1', 'wnohh_cmnty_cli_day1', 'wbelief_masking_effective_day1', 'wbelief_distancing_effective_day1', 'wcovid_vaccinated_friends_day1', 'wlarge_event_indoors_day1', 'wothers_masked_public_day1', 'wothers_distanced_public_day1', 'wshop_indoors_day1', 'wrestaurant_indoors_day1', 'wworried_catch_covid_day1', 'hh_cmnty_cli_day1', 'nohh_cmnty_cli_day1', 'wearing_mask_7d_day1', 'public_transit_day1', 'worried_finances_day1', 'tested_positive_day1', 'cli_day2', 'ili_day2', 'wnohh_cmnty_cli_day2', 'wbelief_masking_effective_day2', 'wbelief_distancing_effective_day2', 'wcovid_vaccinated_friends_day2', 'wlarge_event_indoors_day2', 'wothers_masked_public_day2', 'wothers_distanced_public_day2', 'wshop_indoors_day2', 'wrestaurant_indoors_day2', 'wworried_catch_covid_day2', 'hh_cmnty_cli_day2', 'nohh_cmnty_cli_day2', 'wearing_mask_7d_day2', 'public_transit_day2', 'worried_finances_day2', 'tested_positive_day2'], are not unique in dataframe\n",
            "Execution time: 2 seconds seconds (time limit is 20 minutes).\n",
            "Step 15 completed.\n",
            "Latest Node ID: d73bd7e3d61b4aa39576433790557577\n",
            "Metric: 3.0\n",
            "Is Buggy: True\n",
            "Execution Time: 2.83 seconds\n",
            "Parent Node ID: 17a867fc254a41759ffe5c9f932a2c46\n",
            "Parent Metric: 3.0\n",
            "Parent Is Buggy: True\n",
            "--------------------------------------------------\n",
            "Step 16/20 in progress...\n",
            "传入parse_exer_result的执行结果是: Best parameters for RandomForest: {'model__max_depth': None, 'model__min_samples_split': 10, 'model__n_estimators': 200}\n",
            "Best MSE for RandomForest: 1.0120759563986046\n",
            "Best parameters for GradientBoosting: {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__n_estimators': 100}\n",
            "Best MSE for GradientBoosting: 0.989401535745332\n",
            "Best parameters for SVR: {'model__C': 100, 'model__epsilon': 0.3, 'model__kernel': 'rbf'}\n",
            "Best MSE for SVR: 0.895018895576837\n",
            "Execution time: 7 minutes seconds (time limit is 20 minutes).\n",
            "Step 16 completed.\n",
            "Latest Node ID: c6933eb1f7264915b95f8bd6522f5bdd\n",
            "Metric: 0.895\n",
            "Is Buggy: False\n",
            "Execution Time: 431.01 seconds\n",
            "Parent Node ID: 176aad9d999646d7b2116ad070246504\n",
            "Parent Metric: 0.895\n",
            "Parent Is Buggy: False\n",
            "--------------------------------------------------\n",
            "Step 17/20 in progress...\n",
            "传入parse_exer_result的执行结果是: Best parameters for RandomForest: {'model__max_depth': 20, 'model__min_samples_split': 5, 'model__n_estimators': 200}\n",
            "Best MSE for RandomForest: 1.0140663870366637\n",
            "Best parameters for GradientBoosting: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__n_estimators': 100}\n",
            "Best MSE for GradientBoosting: 0.9877119890573521\n",
            "Best parameters for SVR: {'model__C': 100, 'model__epsilon': 0.3, 'model__kernel': 'rbf'}\n",
            "Best MSE for SVR: 0.895018895576837\n",
            "Execution time: 7 minutes seconds (time limit is 20 minutes).\n",
            "Step 17 completed.\n",
            "Latest Node ID: d32e08d648684d539823021c39049e53\n",
            "Metric: 0.895\n",
            "Is Buggy: False\n",
            "Execution Time: 429.24 seconds\n",
            "Parent Node ID: 176aad9d999646d7b2116ad070246504\n",
            "Parent Metric: 0.895\n",
            "Parent Is Buggy: False\n",
            "--------------------------------------------------\n",
            "Step 18/20 in progress...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-aff6f9c83cd9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-aff6f9c83cd9>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Step {global_step + 1}/{cfg.agent.steps} in progress...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# run agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexec_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexec_callback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;31m# display the latest node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mlatest_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjournal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# 获取最新的节点\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-76b3d1683a73>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, exec_callback)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;31m# 如果父节点没有 bug 且尚未被改进，则进行 improve 操作\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparent_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimprove_flag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0mresult_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_improve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;31m# 如果父节点已经被改进过，则跳过\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-76b3d1683a73>\u001b[0m in \u001b[0;36m_improve\u001b[0;34m(self, parent_node)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0msystem_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msystem_prompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0muser_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mplan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplan_and_code_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msystem_message\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msystem_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_message\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimprove_flag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-76b3d1683a73>\u001b[0m in \u001b[0;36mplan_and_code_query\u001b[0;34m(self, system_message, user_message, retries)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mcompletion_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             response = generate_response(\n\u001b[0m\u001b[1;32m     76\u001b[0m                 \u001b[0mmyModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 _messages=[\n",
            "\u001b[0;32m<ipython-input-5-af18a1d498e9>\u001b[0m in \u001b[0;36mgenerate_response\u001b[0;34m(_model, _messages)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mThis\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mwill\u001b[0m \u001b[0minference\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     '''\n\u001b[0;32m---> 19\u001b[0;31m     _output = _model.create_chat_completion(\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0m_messages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"<|eot_id|>\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"<|end_of_text|>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_cpp/llama.py\u001b[0m in \u001b[0;36mcreate_chat_completion\u001b[0;34m(self, messages, functions, function_call, tools, tool_choice, temperature, top_p, top_k, min_p, typical_p, stream, stop, seed, response_format, max_tokens, presence_penalty, frequency_penalty, repeat_penalty, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, logits_processor, grammar, logit_bias, logprobs, top_logprobs)\u001b[0m\n\u001b[1;32m   1996\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0mllama_chat_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_chat_completion_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m         )\n\u001b[0;32m-> 1998\u001b[0;31m         return handler(\n\u001b[0m\u001b[1;32m   1999\u001b[0m             \u001b[0mllama\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m             \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_cpp/llama_chat_format.py\u001b[0m in \u001b[0;36mchat_completion_handler\u001b[0;34m(llama, messages, functions, function_call, tools, tool_choice, temperature, top_p, top_k, min_p, typical_p, stream, stop, seed, response_format, max_tokens, presence_penalty, frequency_penalty, repeat_penalty, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, logits_processor, grammar, logit_bias, logprobs, top_logprobs, **kwargs)\u001b[0m\n\u001b[1;32m    660\u001b[0m                 )\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m         completion_or_chunks = llama.create_completion(\n\u001b[0m\u001b[1;32m    663\u001b[0m             \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_cpp/llama.py\u001b[0m in \u001b[0;36mcreate_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1830\u001b[0m             \u001b[0mchunks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCreateCompletionStreamResponse\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompletion_or_chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1832\u001b[0;31m         \u001b[0mcompletion\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCompletion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompletion_or_chunks\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1833\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcompletion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_cpp/llama.py\u001b[0m in \u001b[0;36m_create_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1315\u001b[0m         \u001b[0mfinish_reason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"length\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         \u001b[0mmultibyte_fix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m         for token in self.generate(\n\u001b[0m\u001b[1;32m   1318\u001b[0m             \u001b[0mprompt_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_cpp/llama.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, tokens, top_k, top_p, min_p, typical_p, temp, repeat_penalty, reset, frequency_penalty, presence_penalty, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, penalize_nl, logits_processor, stopping_criteria, grammar)\u001b[0m\n\u001b[1;32m    909\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msample_idx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 token = self.sample(\n\u001b[0m\u001b[1;32m    912\u001b[0m                     \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0mtop_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_cpp/llama.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, top_k, top_p, min_p, typical_p, temp, repeat_penalty, frequency_penalty, presence_penalty, tfs_z, mirostat_mode, mirostat_eta, mirostat_tau, penalize_nl, logits_processor, grammar, idx)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m         \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mridx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtmp_sampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_cpp/_internals.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, ctx, idx)\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLlamaContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mllama_cpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllama_sampler_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "def main():\n",
        "\n",
        "    def exec_callback(*args, **kwargs):\n",
        "        res = interpreter.run(*args, **kwargs)\n",
        "        return res\n",
        "\n",
        "    journal = Journal()\n",
        "    agent = Agent(\n",
        "        cfg=cfg,\n",
        "        journal=journal,\n",
        "    )\n",
        "\n",
        "    interpreter = Interpreter()\n",
        "\n",
        "    global_step = len(journal)\n",
        "    while global_step < cfg.agent.steps:\n",
        "        print(f\"Step {global_step + 1}/{cfg.agent.steps} in progress...\")\n",
        "        # run agent\n",
        "        agent.step(exec_callback=exec_callback)\n",
        "        # display the latest node\n",
        "        latest_node = journal.nodes[-1]  # 获取最新的节点\n",
        "        print(f\"Step {global_step + 1} completed.\")\n",
        "        print(f\"Latest Node ID: {latest_node.id}\")\n",
        "        # print(f\"Plan: {latest_node.plan}\")\n",
        "        # print(f\"Code:\\n{wrap_code(latest_node.code)}\")\n",
        "        print(f\"Metric: {latest_node.metric}\")\n",
        "        print(f\"Is Buggy: {latest_node.is_buggy}\")\n",
        "        print(f\"Execution Time: {latest_node.exec_time:.2f} seconds\" if latest_node.exec_time else \"Execution Time: None\")\n",
        "        if latest_node.parent:\n",
        "            parent_node = latest_node.parent\n",
        "            print(f\"Parent Node ID: {parent_node.id}\")\n",
        "            # print(f\"Parent Plan: {parent_node.plan}\")\n",
        "            print(f\"Parent Metric: {parent_node.metric}\")\n",
        "            print(f\"Parent Is Buggy: {parent_node.is_buggy}\")\n",
        "        else:\n",
        "            print(\"Parent Node: None\")\n",
        "        print(\"-\" * 50)\n",
        "        # save results for this iteration\n",
        "        save_run(cfg, journal)\n",
        "        # get current step\n",
        "        global_step = len(journal)\n",
        "\n",
        "    # Kill created child process\n",
        "    interpreter.cleanup_session()\n",
        "\n",
        "\n",
        "    # Kill created child process\n",
        "    interpreter.cleanup_session()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6D_sb1SyBV7",
        "outputId": "770438f0-d83c-44c8-abc7-1c9bbfb9e2a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "COMMAND      PID       USER   FD   TYPE  DEVICE SIZE/OFF NODE NAME\n",
            "jupyter-n 156599 shijunjian   27u  IPv4 2571145      0t0  TCP localhost:35676->localhost:42107 (ESTABLISHED)\n",
            "python    165177 shijunjian   10u  IPv4 2578163      0t0  TCP localhost:42107 (LISTEN)\n",
            "python    165177 shijunjian   17u  IPv4 2579289      0t0  TCP localhost:35668->localhost:42107 (ESTABLISHED)\n",
            "python    165177 shijunjian   18u  IPv4 2579290      0t0  TCP localhost:42107->localhost:35668 (ESTABLISHED)\n",
            "python    165177 shijunjian   48u  IPv4 2579293      0t0  TCP localhost:42107->localhost:35676 (ESTABLISHED)\n"
          ]
        }
      ],
      "source": [
        "!lsof -i :42107"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArUh8ioOyBV8",
        "outputId": "ccea4eeb-c4a3-43a3-c226-e830ba42678a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features: Index(['cli_day1', 'ili_day1', 'wnohh_cmnty_cli_day1',\n",
            "       'wlarge_event_indoors_day1', 'wshop_indoors_day1',\n",
            "       'wrestaurant_indoors_day1', 'hh_cmnty_cli_day1', 'nohh_cmnty_cli_day1',\n",
            "       'tested_positive_day1', 'cli_day2', 'ili_day2', 'wnohh_cmnty_cli_day2',\n",
            "       'wlarge_event_indoors_day2', 'wshop_indoors_day2',\n",
            "       'wrestaurant_indoors_day2', 'hh_cmnty_cli_day2', 'nohh_cmnty_cli_day2',\n",
            "       'tested_positive_day2', 'cli_day3', 'ili_day3', 'wnohh_cmnty_cli_day3',\n",
            "       'wshop_indoors_day3', 'wrestaurant_indoors_day3', 'hh_cmnty_cli_day3',\n",
            "       'nohh_cmnty_cli_day3'],\n",
            "      dtype='object')\n",
            "Selected Features (sorted by importance): [('tested_positive_day2', np.float64(253793.43948971806)), ('tested_positive_day1', np.float64(104538.47795439813)), ('hh_cmnty_cli_day1', np.float64(19075.52592634041)), ('nohh_cmnty_cli_day1', np.float64(18639.652282689876)), ('hh_cmnty_cli_day2', np.float64(16166.43736104487)), ('wnohh_cmnty_cli_day1', np.float64(16016.27875041661)), ('nohh_cmnty_cli_day2', np.float64(15953.931306962195)), ('wnohh_cmnty_cli_day2', np.float64(13740.133089706922)), ('hh_cmnty_cli_day3', np.float64(13530.349564790022)), ('nohh_cmnty_cli_day3', np.float64(13462.968539860403)), ('wnohh_cmnty_cli_day3', np.float64(11652.542259934005)), ('ili_day1', np.float64(10028.05617505164)), ('cli_day1', np.float64(10018.025778104413)), ('cli_day2', np.float64(8813.747945848205)), ('ili_day2', np.float64(8805.560187777804)), ('cli_day3', np.float64(7634.25174299877)), ('ili_day3', np.float64(7616.967884316864)), ('wshop_indoors_day1', np.float64(3004.4317939499874)), ('wshop_indoors_day2', np.float64(2957.6461538583408)), ('wshop_indoors_day3', np.float64(2874.1921529454376)), ('wrestaurant_indoors_day1', np.float64(1465.0912380243196)), ('wrestaurant_indoors_day2', np.float64(1419.92920532845)), ('wrestaurant_indoors_day3', np.float64(1364.6076754755763)), ('wlarge_event_indoors_day2', np.float64(1215.9863567277405)), ('wlarge_event_indoors_day1', np.float64(1210.7338281301948))]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Get your best result!\n",
        "!python best_solution-features.py\n",
        "# !python DSR1.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uD5bPjF5dO2Y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feFaoy8tbvyC"
      },
      "source": [
        "# References\n",
        "The code scripts are from [aideml](https://github.com/WecoAI/aideml) project on github with some modifications.\n",
        "\n",
        "AIDE: AI-Driven Exploration in the Space of Code\n",
        "https://arxiv.org/pdf/2502.13138\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "toc": {
      "base_numbering": 0
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}